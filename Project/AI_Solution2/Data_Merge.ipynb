{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d40a36dd-4cdb-4277-8058-d596f66464dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 가져오기\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import scipy\n",
    "import sklearn\n",
    "import os\n",
    "import chardet\n",
    "\n",
    "# matplotlib 하위 모듈\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# matplotlib 폰트 설정\n",
    "plt.rcParams['font.size'] = 17.5\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
    "plt.rcParams['font.sans-serif'] = ['Malgun Gothic']\n",
    "\n",
    "# 마이너스 폰트 깨짐 방지\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 옵션 설정\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "# 버전 체크\n",
    "# print(pd.__version__)          # 2.1.1\n",
    "# print(np.__version__)          # 1.26.1\n",
    "# print(sns.__version__)         # 0.13.0\n",
    "# print(matplotlib.__version__)  # 3.8.0\n",
    "# print(scipy.__version__)       # 1.11.3\n",
    "# print(sklearn.__version__)     # 1.3.1\n",
    "# print(chardet.__version__)     # 5.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1171107-e6cf-4840-ba9b-af5bcd79a92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit_data.csv의 감지된 인코딩은: EUC-KR 입니다.\n",
    "# Edit_quality.csv의 감지된 인코딩은: UTF-8-SIG 입니다.\n",
    "# Edit_train.csv의 감지된 인코딩은: UTF-8-SIG 입니다.\n",
    "\n",
    "# 데이터 불러오기\n",
    "path = './data/'\n",
    "\n",
    "Data = pd.read_csv(path + 'data_mean.csv', encoding='utf-8')  # A_01 부터 체크\n",
    "A_01 = Data.copy()\n",
    "\n",
    "Quality = pd.read_excel(path + 'quality.xlsx') # B_01 부터 체크\n",
    "B_01 = Quality.copy()\n",
    "\n",
    "# Train = pd.read_csv(path + 'Edit_train.csv', encoding='utf-8-sig') # C_01 부터 체크\n",
    "# C_01 = Train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e497e9-9ecf-4446-8da3-31b3160f2594",
   "metadata": {},
   "source": [
    "### 스탠다드 스케일러를 이용한 모델 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3efbe65-416f-46f0-8b7e-4866c871a8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2939722 entries, 0 to 2939721\n",
      "Data columns (total 20 columns):\n",
      " #   Column     Dtype  \n",
      "---  ------     -----  \n",
      " 0   TAG_MIN    object \n",
      " 1   AN         int64  \n",
      " 2   DZ1_OP     float64\n",
      " 3   DZ2_OP     float64\n",
      " 4   DZ1_TEMP   float64\n",
      " 5   DZ2_TEMP   float64\n",
      " 6   CLEAN      float64\n",
      " 7   HDZ1_OP    float64\n",
      " 8   HDZ2_OP    float64\n",
      " 9   HDZ3_OP    float64\n",
      " 10  HDZ4_OP    float64\n",
      " 11  HDZ_CP     float64\n",
      " 12  HDZ1_TEMP  float64\n",
      " 13  HDZ2_TEMP  float64\n",
      " 14  HDZ3_TEMP  float64\n",
      " 15  HDZ4_TEMP  float64\n",
      " 16  SCZ1_TEMP  float64\n",
      " 17  SCZ2_TEMP  float64\n",
      " 18  STZ1_TEMP  float64\n",
      " 19  STZ2_TEMP  float64\n",
      "dtypes: float64(18), int64(1), object(1)\n",
      "memory usage: 448.6+ MB\n"
     ]
    }
   ],
   "source": [
    "Stand_A_01_01 = A_01.copy()\n",
    "Stand_A_01_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ff876ca-ba29-4fbc-a25b-af983cccb844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN</th>\n",
       "      <th>DZ1_OP</th>\n",
       "      <th>DZ2_OP</th>\n",
       "      <th>DZ1_TEMP</th>\n",
       "      <th>DZ2_TEMP</th>\n",
       "      <th>CLEAN</th>\n",
       "      <th>HDZ1_OP</th>\n",
       "      <th>HDZ2_OP</th>\n",
       "      <th>HDZ3_OP</th>\n",
       "      <th>HDZ4_OP</th>\n",
       "      <th>HDZ_CP</th>\n",
       "      <th>HDZ1_TEMP</th>\n",
       "      <th>HDZ2_TEMP</th>\n",
       "      <th>HDZ3_TEMP</th>\n",
       "      <th>HDZ4_TEMP</th>\n",
       "      <th>SCZ1_TEMP</th>\n",
       "      <th>SCZ2_TEMP</th>\n",
       "      <th>STZ1_TEMP</th>\n",
       "      <th>STZ2_TEMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "      <td>2939722.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>128442.2464</td>\n",
       "      <td>69.8940</td>\n",
       "      <td>20.4471</td>\n",
       "      <td>100.0061</td>\n",
       "      <td>100.0198</td>\n",
       "      <td>67.7186</td>\n",
       "      <td>75.6437</td>\n",
       "      <td>54.8624</td>\n",
       "      <td>53.8603</td>\n",
       "      <td>71.0893</td>\n",
       "      <td>0.4489</td>\n",
       "      <td>859.2077</td>\n",
       "      <td>860.0021</td>\n",
       "      <td>860.0029</td>\n",
       "      <td>860.0062</td>\n",
       "      <td>283.9963</td>\n",
       "      <td>279.9293</td>\n",
       "      <td>331.8062</td>\n",
       "      <td>332.1773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12637.0445</td>\n",
       "      <td>4.0148</td>\n",
       "      <td>5.2171</td>\n",
       "      <td>0.4360</td>\n",
       "      <td>0.3623</td>\n",
       "      <td>1.6307</td>\n",
       "      <td>25.1425</td>\n",
       "      <td>4.4291</td>\n",
       "      <td>2.6643</td>\n",
       "      <td>2.5570</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>3.6476</td>\n",
       "      <td>0.5578</td>\n",
       "      <td>0.3518</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>9.5126</td>\n",
       "      <td>6.6114</td>\n",
       "      <td>0.7827</td>\n",
       "      <td>0.8733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102410.0000</td>\n",
       "      <td>47.2532</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>97.3421</td>\n",
       "      <td>97.8706</td>\n",
       "      <td>60.6244</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>8.6200</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>840.2980</td>\n",
       "      <td>855.9290</td>\n",
       "      <td>858.2800</td>\n",
       "      <td>857.9920</td>\n",
       "      <td>266.2300</td>\n",
       "      <td>266.4260</td>\n",
       "      <td>328.1610</td>\n",
       "      <td>328.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>119448.0000</td>\n",
       "      <td>68.4288</td>\n",
       "      <td>18.9176</td>\n",
       "      <td>99.8145</td>\n",
       "      <td>99.8901</td>\n",
       "      <td>66.5695</td>\n",
       "      <td>65.0094</td>\n",
       "      <td>53.3259</td>\n",
       "      <td>52.3891</td>\n",
       "      <td>69.6781</td>\n",
       "      <td>0.4484</td>\n",
       "      <td>857.9490</td>\n",
       "      <td>859.7760</td>\n",
       "      <td>859.8290</td>\n",
       "      <td>859.8430</td>\n",
       "      <td>274.7540</td>\n",
       "      <td>273.5030</td>\n",
       "      <td>331.8670</td>\n",
       "      <td>332.1780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>129889.0000</td>\n",
       "      <td>70.5166</td>\n",
       "      <td>21.2931</td>\n",
       "      <td>100.0020</td>\n",
       "      <td>100.0190</td>\n",
       "      <td>67.6974</td>\n",
       "      <td>82.1768</td>\n",
       "      <td>55.6654</td>\n",
       "      <td>53.8862</td>\n",
       "      <td>71.0454</td>\n",
       "      <td>0.4501</td>\n",
       "      <td>859.5740</td>\n",
       "      <td>860.0220</td>\n",
       "      <td>860.0020</td>\n",
       "      <td>860.0000</td>\n",
       "      <td>284.5850</td>\n",
       "      <td>280.0190</td>\n",
       "      <td>332.0170</td>\n",
       "      <td>332.4230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139116.0000</td>\n",
       "      <td>72.3781</td>\n",
       "      <td>23.3884</td>\n",
       "      <td>100.1910</td>\n",
       "      <td>100.1610</td>\n",
       "      <td>68.9798</td>\n",
       "      <td>95.3422</td>\n",
       "      <td>57.5733</td>\n",
       "      <td>55.4145</td>\n",
       "      <td>72.4771</td>\n",
       "      <td>0.4517</td>\n",
       "      <td>860.2580</td>\n",
       "      <td>860.2490</td>\n",
       "      <td>860.1720</td>\n",
       "      <td>860.1580</td>\n",
       "      <td>293.3430</td>\n",
       "      <td>286.3340</td>\n",
       "      <td>332.1410</td>\n",
       "      <td>332.6260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>148069.0000</td>\n",
       "      <td>87.2995</td>\n",
       "      <td>47.5395</td>\n",
       "      <td>102.4690</td>\n",
       "      <td>101.8430</td>\n",
       "      <td>71.4901</td>\n",
       "      <td>100.0000</td>\n",
       "      <td>77.2709</td>\n",
       "      <td>66.0150</td>\n",
       "      <td>87.3907</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>877.2280</td>\n",
       "      <td>866.0340</td>\n",
       "      <td>870.1190</td>\n",
       "      <td>882.1480</td>\n",
       "      <td>298.5300</td>\n",
       "      <td>291.6960</td>\n",
       "      <td>332.7170</td>\n",
       "      <td>333.1790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AN       DZ1_OP       DZ2_OP     DZ1_TEMP     DZ2_TEMP  \\\n",
       "count 2939722.0000 2939722.0000 2939722.0000 2939722.0000 2939722.0000   \n",
       "mean   128442.2464      69.8940      20.4471     100.0061     100.0198   \n",
       "std     12637.0445       4.0148       5.2171       0.4360       0.3623   \n",
       "min    102410.0000      47.2532       0.0001      97.3421      97.8706   \n",
       "25%    119448.0000      68.4288      18.9176      99.8145      99.8901   \n",
       "50%    129889.0000      70.5166      21.2931     100.0020     100.0190   \n",
       "75%    139116.0000      72.3781      23.3884     100.1910     100.1610   \n",
       "max    148069.0000      87.2995      47.5395     102.4690     101.8430   \n",
       "\n",
       "             CLEAN      HDZ1_OP      HDZ2_OP      HDZ3_OP      HDZ4_OP  \\\n",
       "count 2939722.0000 2939722.0000 2939722.0000 2939722.0000 2939722.0000   \n",
       "mean       67.7186      75.6437      54.8624      53.8603      71.0893   \n",
       "std         1.6307      25.1425       4.4291       2.6643       2.5570   \n",
       "min        60.6244       0.0009       8.6200       0.0437       0.0062   \n",
       "25%        66.5695      65.0094      53.3259      52.3891      69.6781   \n",
       "50%        67.6974      82.1768      55.6654      53.8862      71.0454   \n",
       "75%        68.9798      95.3422      57.5733      55.4145      72.4771   \n",
       "max        71.4901     100.0000      77.2709      66.0150      87.3907   \n",
       "\n",
       "            HDZ_CP    HDZ1_TEMP    HDZ2_TEMP    HDZ3_TEMP    HDZ4_TEMP  \\\n",
       "count 2939722.0000 2939722.0000 2939722.0000 2939722.0000 2939722.0000   \n",
       "mean        0.4489     859.2077     860.0021     860.0029     860.0062   \n",
       "std         0.0189       3.6476       0.5578       0.3518       0.4552   \n",
       "min         0.0051     840.2980     855.9290     858.2800     857.9920   \n",
       "25%         0.4484     857.9490     859.7760     859.8290     859.8430   \n",
       "50%         0.4501     859.5740     860.0220     860.0020     860.0000   \n",
       "75%         0.4517     860.2580     860.2490     860.1720     860.1580   \n",
       "max         0.9091     877.2280     866.0340     870.1190     882.1480   \n",
       "\n",
       "         SCZ1_TEMP    SCZ2_TEMP    STZ1_TEMP    STZ2_TEMP  \n",
       "count 2939722.0000 2939722.0000 2939722.0000 2939722.0000  \n",
       "mean      283.9963     279.9293     331.8062     332.1773  \n",
       "std         9.5126       6.6114       0.7827       0.8733  \n",
       "min       266.2300     266.4260     328.1610     328.0730  \n",
       "25%       274.7540     273.5030     331.8670     332.1780  \n",
       "50%       284.5850     280.0190     332.0170     332.4230  \n",
       "75%       293.3430     286.3340     332.1410     332.6260  \n",
       "max       298.5300     291.6960     332.7170     333.1790  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HDZ_CPM: 소입로 CP 모니터 값 0으로 채워져있음\n",
    "Stand_A_01_01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90a565f-5ffe-43f4-a050-86abb3190276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDZ_CPM: mean, std, min, 25%, 50%, 75%, max == 0 이므로 무의미한 컬럼이므로 삭제하도록 함\n",
    "# Stand_A_01_02 = Stand_A_01_01.drop(['HDZ_CPM'], axis=1)\n",
    "# Stand_A_01_02.head(1)\n",
    "Stand_A_01_02 = Stand_A_01_01.copy()\n",
    "Stand_A_01_02.drop(['TAG_MIN'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f101f07f-96ea-4871-a5aa-490bb25cd85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          102410\n",
       "1          102410\n",
       "2          102410\n",
       "3          102410\n",
       "4          102410\n",
       "            ...  \n",
       "2939717    148069\n",
       "2939718    148069\n",
       "2939719    148069\n",
       "2939720    148069\n",
       "2939721    148069\n",
       "Name: AN, Length: 2939722, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AN(배정번호) 정수값으로 변환\n",
    "Stand_A_01_03 = Stand_A_01_02.copy()\n",
    "Stand_A_01_03['AN'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a177989-8283-426b-8191-9c12504fa3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AN           0\n",
       "DZ1_OP       0\n",
       "DZ2_OP       0\n",
       "DZ1_TEMP     0\n",
       "DZ2_TEMP     0\n",
       "CLEAN        0\n",
       "HDZ1_OP      0\n",
       "HDZ2_OP      0\n",
       "HDZ3_OP      0\n",
       "HDZ4_OP      0\n",
       "HDZ_CP       0\n",
       "HDZ1_TEMP    0\n",
       "HDZ2_TEMP    0\n",
       "HDZ3_TEMP    0\n",
       "HDZ4_TEMP    0\n",
       "SCZ1_TEMP    0\n",
       "SCZ2_TEMP    0\n",
       "STZ1_TEMP    0\n",
       "STZ2_TEMP    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 체크\n",
    "Stand_A_01_03.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600ce9c3-2531-45dd-b7a4-ad3a442a1ced",
   "metadata": {},
   "source": [
    "### 02. Merge전 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5b6459-232e-42fc-a30c-e5128b5bd683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">DZ1_OP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DZ2_OP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DZ1_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">DZ2_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">CLEAN</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ1_OP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ2_OP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ3_OP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ4_OP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ_CP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ1_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ2_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ3_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">HDZ4_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SCZ1_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">SCZ2_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">STZ1_TEMP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">STZ2_TEMP</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AN</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102410</th>\n",
       "      <td>72.2527</td>\n",
       "      <td>3.6965</td>\n",
       "      <td>21.3545</td>\n",
       "      <td>4.3489</td>\n",
       "      <td>99.9435</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>100.0619</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>69.6026</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>75.7122</td>\n",
       "      <td>22.9797</td>\n",
       "      <td>59.3326</td>\n",
       "      <td>1.7839</td>\n",
       "      <td>50.6809</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>70.2494</td>\n",
       "      <td>2.5042</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>859.4869</td>\n",
       "      <td>3.5738</td>\n",
       "      <td>860.0124</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>860.0098</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>860.0106</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>282.5815</td>\n",
       "      <td>9.3711</td>\n",
       "      <td>280.1490</td>\n",
       "      <td>6.0339</td>\n",
       "      <td>329.0163</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>329.0709</td>\n",
       "      <td>0.1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102585</th>\n",
       "      <td>72.2356</td>\n",
       "      <td>3.3650</td>\n",
       "      <td>18.6026</td>\n",
       "      <td>2.8597</td>\n",
       "      <td>99.9874</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>100.0650</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>69.5912</td>\n",
       "      <td>1.0642</td>\n",
       "      <td>74.8979</td>\n",
       "      <td>23.4053</td>\n",
       "      <td>59.1689</td>\n",
       "      <td>1.9203</td>\n",
       "      <td>52.0143</td>\n",
       "      <td>1.4977</td>\n",
       "      <td>70.6397</td>\n",
       "      <td>2.2398</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>859.3333</td>\n",
       "      <td>3.0190</td>\n",
       "      <td>860.0086</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>859.9898</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>859.9918</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>282.7882</td>\n",
       "      <td>9.4996</td>\n",
       "      <td>279.7723</td>\n",
       "      <td>7.1615</td>\n",
       "      <td>328.9986</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>328.9242</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102930</th>\n",
       "      <td>70.7202</td>\n",
       "      <td>3.2318</td>\n",
       "      <td>20.9119</td>\n",
       "      <td>2.5821</td>\n",
       "      <td>99.9956</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>100.0216</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>69.5295</td>\n",
       "      <td>1.0979</td>\n",
       "      <td>70.7003</td>\n",
       "      <td>23.6703</td>\n",
       "      <td>45.8490</td>\n",
       "      <td>2.1012</td>\n",
       "      <td>48.2632</td>\n",
       "      <td>1.4201</td>\n",
       "      <td>67.1299</td>\n",
       "      <td>2.1310</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>859.6424</td>\n",
       "      <td>2.8268</td>\n",
       "      <td>859.9879</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>859.9960</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>860.0075</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>283.3309</td>\n",
       "      <td>9.6804</td>\n",
       "      <td>279.3090</td>\n",
       "      <td>6.6652</td>\n",
       "      <td>329.1336</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>329.1488</td>\n",
       "      <td>0.1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103142</th>\n",
       "      <td>72.4242</td>\n",
       "      <td>2.6352</td>\n",
       "      <td>22.2502</td>\n",
       "      <td>2.4028</td>\n",
       "      <td>100.0051</td>\n",
       "      <td>0.3314</td>\n",
       "      <td>100.0097</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>69.5369</td>\n",
       "      <td>1.0643</td>\n",
       "      <td>77.3254</td>\n",
       "      <td>15.4611</td>\n",
       "      <td>46.0317</td>\n",
       "      <td>1.5804</td>\n",
       "      <td>50.5714</td>\n",
       "      <td>1.2435</td>\n",
       "      <td>69.4428</td>\n",
       "      <td>1.7862</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>859.8549</td>\n",
       "      <td>1.5416</td>\n",
       "      <td>859.9955</td>\n",
       "      <td>0.2466</td>\n",
       "      <td>859.9969</td>\n",
       "      <td>0.1886</td>\n",
       "      <td>860.0035</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>282.8823</td>\n",
       "      <td>9.4955</td>\n",
       "      <td>279.2411</td>\n",
       "      <td>6.5374</td>\n",
       "      <td>329.0821</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>329.0732</td>\n",
       "      <td>0.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103675</th>\n",
       "      <td>72.7746</td>\n",
       "      <td>4.1592</td>\n",
       "      <td>21.8652</td>\n",
       "      <td>3.6228</td>\n",
       "      <td>99.9835</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>100.0437</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>69.3210</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>74.7738</td>\n",
       "      <td>23.5540</td>\n",
       "      <td>45.1690</td>\n",
       "      <td>1.5090</td>\n",
       "      <td>50.2557</td>\n",
       "      <td>1.7672</td>\n",
       "      <td>69.7685</td>\n",
       "      <td>2.7004</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>859.8177</td>\n",
       "      <td>3.6836</td>\n",
       "      <td>859.9567</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>860.0242</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>860.0072</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>283.5816</td>\n",
       "      <td>9.7056</td>\n",
       "      <td>277.5448</td>\n",
       "      <td>5.3659</td>\n",
       "      <td>329.0109</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>329.1145</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DZ1_OP         DZ2_OP        DZ1_TEMP        DZ2_TEMP          CLEAN  \\\n",
       "          mean    std    mean    std     mean    std     mean    std    mean   \n",
       "AN                                                                             \n",
       "102410 72.2527 3.6965 21.3545 4.3489  99.9435 0.5939 100.0619 0.4835 69.6026   \n",
       "102585 72.2356 3.3650 18.6026 2.8597  99.9874 0.5154 100.0650 0.3561 69.5912   \n",
       "102930 70.7202 3.2318 20.9119 2.5821  99.9956 0.4727 100.0216 0.3430 69.5295   \n",
       "103142 72.4242 2.6352 22.2502 2.4028 100.0051 0.3314 100.0097 0.2518 69.5369   \n",
       "103675 72.7746 4.1592 21.8652 3.6228  99.9835 0.6553 100.0437 0.4707 69.3210   \n",
       "\n",
       "              HDZ1_OP         HDZ2_OP        HDZ3_OP        HDZ4_OP         \\\n",
       "          std    mean     std    mean    std    mean    std    mean    std   \n",
       "AN                                                                           \n",
       "102410 0.8454 75.7122 22.9797 59.3326 1.7839 50.6809 1.4400 70.2494 2.5042   \n",
       "102585 1.0642 74.8979 23.4053 59.1689 1.9203 52.0143 1.4977 70.6397 2.2398   \n",
       "102930 1.0979 70.7003 23.6703 45.8490 2.1012 48.2632 1.4201 67.1299 2.1310   \n",
       "103142 1.0643 77.3254 15.4611 46.0317 1.5804 50.5714 1.2435 69.4428 1.7862   \n",
       "103675 0.9917 74.7738 23.5540 45.1690 1.5090 50.2557 1.7672 69.7685 2.7004   \n",
       "\n",
       "       HDZ_CP        HDZ1_TEMP        HDZ2_TEMP        HDZ3_TEMP         \\\n",
       "         mean    std      mean    std      mean    std      mean    std   \n",
       "AN                                                                        \n",
       "102410 0.4505 0.0059  859.4869 3.5738  860.0124 0.4007  860.0098 0.2816   \n",
       "102585 0.4502 0.0028  859.3333 3.0190  860.0086 0.4035  859.9898 0.2411   \n",
       "102930 0.4493 0.0059  859.6424 2.8268  859.9879 0.3844  859.9960 0.2419   \n",
       "103142 0.4498 0.0040  859.8549 1.5416  859.9955 0.2466  859.9969 0.1886   \n",
       "103675 0.4500 0.0030  859.8177 3.6836  859.9567 0.2956  860.0242 0.3190   \n",
       "\n",
       "       HDZ4_TEMP        SCZ1_TEMP        SCZ2_TEMP        STZ1_TEMP         \\\n",
       "            mean    std      mean    std      mean    std      mean    std   \n",
       "AN                                                                           \n",
       "102410  860.0106 0.5534  282.5815 9.3711  280.1490 6.0339  329.0163 0.1270   \n",
       "102585  859.9918 0.4805  282.7882 9.4996  279.7723 7.1615  328.9986 0.1012   \n",
       "102930  860.0075 0.4184  283.3309 9.6804  279.3090 6.6652  329.1336 0.1212   \n",
       "103142  860.0035 0.2967  282.8823 9.4955  279.2411 6.5374  329.0821 0.1000   \n",
       "103675  860.0072 0.5712  283.5816 9.7056  277.5448 5.3659  329.0109 0.0967   \n",
       "\n",
       "       STZ2_TEMP         \n",
       "            mean    std  \n",
       "AN                       \n",
       "102410  329.0709 0.1220  \n",
       "102585  328.9242 0.0891  \n",
       "102930  329.1488 0.1170  \n",
       "103142  329.0732 0.1020  \n",
       "103675  329.1145 0.0879  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stand_A_02_01 = Stand_A_01_03.groupby(['AN']).agg(['mean', 'std'])\n",
    "Stand_A_02_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee56ac1-3865-4ab5-84c0-416aebcf7459",
   "metadata": {},
   "outputs": [],
   "source": [
    "chg_name = {'mean':'_AVG', 'std': '_Std'}\n",
    "Stand_A_02_01.columns = list(map(lambda x: x[0] + chg_name[x[1]], Stand_A_02_01.columns))\n",
    "\n",
    "Stand_A_02_01.reset_index(drop=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc59a8f-2223-4e5d-a2b7-89e493b8b369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN</th>\n",
       "      <th>DZ1_OP_AVG</th>\n",
       "      <th>DZ1_OP_Std</th>\n",
       "      <th>DZ2_OP_AVG</th>\n",
       "      <th>DZ2_OP_Std</th>\n",
       "      <th>DZ1_TEMP_AVG</th>\n",
       "      <th>DZ1_TEMP_Std</th>\n",
       "      <th>DZ2_TEMP_AVG</th>\n",
       "      <th>DZ2_TEMP_Std</th>\n",
       "      <th>CLEAN_AVG</th>\n",
       "      <th>CLEAN_Std</th>\n",
       "      <th>HDZ1_OP_AVG</th>\n",
       "      <th>HDZ1_OP_Std</th>\n",
       "      <th>HDZ2_OP_AVG</th>\n",
       "      <th>HDZ2_OP_Std</th>\n",
       "      <th>HDZ3_OP_AVG</th>\n",
       "      <th>HDZ3_OP_Std</th>\n",
       "      <th>HDZ4_OP_AVG</th>\n",
       "      <th>HDZ4_OP_Std</th>\n",
       "      <th>HDZ_CP_AVG</th>\n",
       "      <th>HDZ_CP_Std</th>\n",
       "      <th>HDZ1_TEMP_AVG</th>\n",
       "      <th>HDZ1_TEMP_Std</th>\n",
       "      <th>HDZ2_TEMP_AVG</th>\n",
       "      <th>HDZ2_TEMP_Std</th>\n",
       "      <th>HDZ3_TEMP_AVG</th>\n",
       "      <th>HDZ3_TEMP_Std</th>\n",
       "      <th>HDZ4_TEMP_AVG</th>\n",
       "      <th>HDZ4_TEMP_Std</th>\n",
       "      <th>SCZ1_TEMP_AVG</th>\n",
       "      <th>SCZ1_TEMP_Std</th>\n",
       "      <th>SCZ2_TEMP_AVG</th>\n",
       "      <th>SCZ2_TEMP_Std</th>\n",
       "      <th>STZ1_TEMP_AVG</th>\n",
       "      <th>STZ1_TEMP_Std</th>\n",
       "      <th>STZ2_TEMP_AVG</th>\n",
       "      <th>STZ2_TEMP_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102410</td>\n",
       "      <td>72.2527</td>\n",
       "      <td>3.6965</td>\n",
       "      <td>21.3545</td>\n",
       "      <td>4.3489</td>\n",
       "      <td>99.9435</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>100.0619</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>69.6026</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>75.7122</td>\n",
       "      <td>22.9797</td>\n",
       "      <td>59.3326</td>\n",
       "      <td>1.7839</td>\n",
       "      <td>50.6809</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>70.2494</td>\n",
       "      <td>2.5042</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>859.4869</td>\n",
       "      <td>3.5738</td>\n",
       "      <td>860.0124</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>860.0098</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>860.0106</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>282.5815</td>\n",
       "      <td>9.3711</td>\n",
       "      <td>280.1490</td>\n",
       "      <td>6.0339</td>\n",
       "      <td>329.0163</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>329.0709</td>\n",
       "      <td>0.1220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AN  DZ1_OP_AVG  DZ1_OP_Std  DZ2_OP_AVG  DZ2_OP_Std  DZ1_TEMP_AVG  \\\n",
       "0  102410     72.2527      3.6965     21.3545      4.3489       99.9435   \n",
       "\n",
       "   DZ1_TEMP_Std  DZ2_TEMP_AVG  DZ2_TEMP_Std  CLEAN_AVG  CLEAN_Std  \\\n",
       "0        0.5939      100.0619        0.4835    69.6026     0.8454   \n",
       "\n",
       "   HDZ1_OP_AVG  HDZ1_OP_Std  HDZ2_OP_AVG  HDZ2_OP_Std  HDZ3_OP_AVG  \\\n",
       "0      75.7122      22.9797      59.3326       1.7839      50.6809   \n",
       "\n",
       "   HDZ3_OP_Std  HDZ4_OP_AVG  HDZ4_OP_Std  HDZ_CP_AVG  HDZ_CP_Std  \\\n",
       "0       1.4400      70.2494       2.5042      0.4505      0.0059   \n",
       "\n",
       "   HDZ1_TEMP_AVG  HDZ1_TEMP_Std  HDZ2_TEMP_AVG  HDZ2_TEMP_Std  HDZ3_TEMP_AVG  \\\n",
       "0       859.4869         3.5738       860.0124         0.4007       860.0098   \n",
       "\n",
       "   HDZ3_TEMP_Std  HDZ4_TEMP_AVG  HDZ4_TEMP_Std  SCZ1_TEMP_AVG  SCZ1_TEMP_Std  \\\n",
       "0         0.2816       860.0106         0.5534       282.5815         9.3711   \n",
       "\n",
       "   SCZ2_TEMP_AVG  SCZ2_TEMP_Std  STZ1_TEMP_AVG  STZ1_TEMP_Std  STZ2_TEMP_AVG  \\\n",
       "0       280.1490         6.0339       329.0163         0.1270       329.0709   \n",
       "\n",
       "   STZ2_TEMP_Std  \n",
       "0         0.1220  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stand_A_02_01.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "531d46bb-a1eb-4a93-9ce4-4987defc98de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136 entries, 0 to 135\n",
      "Data columns (total 37 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   AN             136 non-null    int64  \n",
      " 1   DZ1_OP_AVG     136 non-null    float64\n",
      " 2   DZ1_OP_Std     136 non-null    float64\n",
      " 3   DZ2_OP_AVG     136 non-null    float64\n",
      " 4   DZ2_OP_Std     136 non-null    float64\n",
      " 5   DZ1_TEMP_AVG   136 non-null    float64\n",
      " 6   DZ1_TEMP_Std   136 non-null    float64\n",
      " 7   DZ2_TEMP_AVG   136 non-null    float64\n",
      " 8   DZ2_TEMP_Std   136 non-null    float64\n",
      " 9   CLEAN_AVG      136 non-null    float64\n",
      " 10  CLEAN_Std      136 non-null    float64\n",
      " 11  HDZ1_OP_AVG    136 non-null    float64\n",
      " 12  HDZ1_OP_Std    136 non-null    float64\n",
      " 13  HDZ2_OP_AVG    136 non-null    float64\n",
      " 14  HDZ2_OP_Std    136 non-null    float64\n",
      " 15  HDZ3_OP_AVG    136 non-null    float64\n",
      " 16  HDZ3_OP_Std    136 non-null    float64\n",
      " 17  HDZ4_OP_AVG    136 non-null    float64\n",
      " 18  HDZ4_OP_Std    136 non-null    float64\n",
      " 19  HDZ_CP_AVG     136 non-null    float64\n",
      " 20  HDZ_CP_Std     136 non-null    float64\n",
      " 21  HDZ1_TEMP_AVG  136 non-null    float64\n",
      " 22  HDZ1_TEMP_Std  136 non-null    float64\n",
      " 23  HDZ2_TEMP_AVG  136 non-null    float64\n",
      " 24  HDZ2_TEMP_Std  136 non-null    float64\n",
      " 25  HDZ3_TEMP_AVG  136 non-null    float64\n",
      " 26  HDZ3_TEMP_Std  136 non-null    float64\n",
      " 27  HDZ4_TEMP_AVG  136 non-null    float64\n",
      " 28  HDZ4_TEMP_Std  136 non-null    float64\n",
      " 29  SCZ1_TEMP_AVG  136 non-null    float64\n",
      " 30  SCZ1_TEMP_Std  136 non-null    float64\n",
      " 31  SCZ2_TEMP_AVG  136 non-null    float64\n",
      " 32  SCZ2_TEMP_Std  136 non-null    float64\n",
      " 33  STZ1_TEMP_AVG  136 non-null    float64\n",
      " 34  STZ1_TEMP_Std  136 non-null    float64\n",
      " 35  STZ2_TEMP_AVG  136 non-null    float64\n",
      " 36  STZ2_TEMP_Std  136 non-null    float64\n",
      "dtypes: float64(36), int64(1)\n",
      "memory usage: 39.4 KB\n"
     ]
    }
   ],
   "source": [
    "Stand_A_02_01.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e77a3e81-fd41-4ddf-82fc-f9e3ae468066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN</th>\n",
       "      <th>DZ1_OP_AVG</th>\n",
       "      <th>DZ1_OP_Std</th>\n",
       "      <th>DZ2_OP_AVG</th>\n",
       "      <th>DZ2_OP_Std</th>\n",
       "      <th>DZ1_TEMP_AVG</th>\n",
       "      <th>DZ1_TEMP_Std</th>\n",
       "      <th>DZ2_TEMP_AVG</th>\n",
       "      <th>DZ2_TEMP_Std</th>\n",
       "      <th>CLEAN_AVG</th>\n",
       "      <th>CLEAN_Std</th>\n",
       "      <th>HDZ1_OP_AVG</th>\n",
       "      <th>HDZ1_OP_Std</th>\n",
       "      <th>HDZ2_OP_AVG</th>\n",
       "      <th>HDZ2_OP_Std</th>\n",
       "      <th>HDZ3_OP_AVG</th>\n",
       "      <th>HDZ3_OP_Std</th>\n",
       "      <th>HDZ4_OP_AVG</th>\n",
       "      <th>HDZ4_OP_Std</th>\n",
       "      <th>HDZ_CP_AVG</th>\n",
       "      <th>HDZ_CP_Std</th>\n",
       "      <th>HDZ1_TEMP_AVG</th>\n",
       "      <th>HDZ1_TEMP_Std</th>\n",
       "      <th>HDZ2_TEMP_AVG</th>\n",
       "      <th>HDZ2_TEMP_Std</th>\n",
       "      <th>HDZ3_TEMP_AVG</th>\n",
       "      <th>HDZ3_TEMP_Std</th>\n",
       "      <th>HDZ4_TEMP_AVG</th>\n",
       "      <th>HDZ4_TEMP_Std</th>\n",
       "      <th>SCZ1_TEMP_AVG</th>\n",
       "      <th>SCZ1_TEMP_Std</th>\n",
       "      <th>SCZ2_TEMP_AVG</th>\n",
       "      <th>SCZ2_TEMP_Std</th>\n",
       "      <th>STZ1_TEMP_AVG</th>\n",
       "      <th>STZ1_TEMP_Std</th>\n",
       "      <th>STZ2_TEMP_AVG</th>\n",
       "      <th>STZ2_TEMP_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "      <td>136.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>128897.1912</td>\n",
       "      <td>69.9161</td>\n",
       "      <td>3.4442</td>\n",
       "      <td>20.7351</td>\n",
       "      <td>3.3756</td>\n",
       "      <td>100.0046</td>\n",
       "      <td>0.4568</td>\n",
       "      <td>100.0135</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>67.7910</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>75.3717</td>\n",
       "      <td>24.7103</td>\n",
       "      <td>55.0219</td>\n",
       "      <td>2.7603</td>\n",
       "      <td>53.9568</td>\n",
       "      <td>1.8428</td>\n",
       "      <td>71.0287</td>\n",
       "      <td>1.8287</td>\n",
       "      <td>0.4479</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>859.1973</td>\n",
       "      <td>3.6437</td>\n",
       "      <td>860.0031</td>\n",
       "      <td>0.5663</td>\n",
       "      <td>860.0051</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>860.0074</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>284.0018</td>\n",
       "      <td>9.4269</td>\n",
       "      <td>280.0161</td>\n",
       "      <td>6.5432</td>\n",
       "      <td>331.7992</td>\n",
       "      <td>0.1358</td>\n",
       "      <td>332.1629</td>\n",
       "      <td>0.1571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12403.3939</td>\n",
       "      <td>1.9839</td>\n",
       "      <td>0.6989</td>\n",
       "      <td>3.6314</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>1.5089</td>\n",
       "      <td>0.3317</td>\n",
       "      <td>6.3654</td>\n",
       "      <td>5.1960</td>\n",
       "      <td>3.3286</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>1.7844</td>\n",
       "      <td>0.7529</td>\n",
       "      <td>1.4340</td>\n",
       "      <td>1.0587</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.6014</td>\n",
       "      <td>1.3147</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>0.7635</td>\n",
       "      <td>0.7131</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>0.7910</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.8774</td>\n",
       "      <td>0.0882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102410.0000</td>\n",
       "      <td>62.9142</td>\n",
       "      <td>1.4303</td>\n",
       "      <td>4.3665</td>\n",
       "      <td>1.3248</td>\n",
       "      <td>99.3702</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>98.8638</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>64.6216</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>51.4322</td>\n",
       "      <td>2.5605</td>\n",
       "      <td>43.3118</td>\n",
       "      <td>0.9948</td>\n",
       "      <td>47.3185</td>\n",
       "      <td>0.9472</td>\n",
       "      <td>66.4568</td>\n",
       "      <td>0.9160</td>\n",
       "      <td>0.3411</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>856.5440</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>859.8996</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>859.9213</td>\n",
       "      <td>0.1208</td>\n",
       "      <td>859.9477</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>280.9212</td>\n",
       "      <td>1.4632</td>\n",
       "      <td>277.5448</td>\n",
       "      <td>1.0366</td>\n",
       "      <td>328.8319</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>328.9242</td>\n",
       "      <td>0.0370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>120467.7500</td>\n",
       "      <td>68.9546</td>\n",
       "      <td>2.9770</td>\n",
       "      <td>19.4396</td>\n",
       "      <td>2.6984</td>\n",
       "      <td>99.9957</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>99.9990</td>\n",
       "      <td>0.2865</td>\n",
       "      <td>66.5691</td>\n",
       "      <td>0.3927</td>\n",
       "      <td>73.3242</td>\n",
       "      <td>22.1210</td>\n",
       "      <td>54.3702</td>\n",
       "      <td>2.2204</td>\n",
       "      <td>53.2812</td>\n",
       "      <td>1.5798</td>\n",
       "      <td>70.1344</td>\n",
       "      <td>1.6037</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>858.8570</td>\n",
       "      <td>2.7201</td>\n",
       "      <td>859.9934</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>859.9940</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>859.9954</td>\n",
       "      <td>0.2923</td>\n",
       "      <td>283.5871</td>\n",
       "      <td>9.3505</td>\n",
       "      <td>279.6242</td>\n",
       "      <td>6.3677</td>\n",
       "      <td>331.9165</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>332.1647</td>\n",
       "      <td>0.1017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>130199.0000</td>\n",
       "      <td>69.8206</td>\n",
       "      <td>3.4286</td>\n",
       "      <td>21.2772</td>\n",
       "      <td>3.2869</td>\n",
       "      <td>100.0026</td>\n",
       "      <td>0.4446</td>\n",
       "      <td>100.0116</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>67.8474</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>76.1939</td>\n",
       "      <td>24.7874</td>\n",
       "      <td>55.6828</td>\n",
       "      <td>2.7285</td>\n",
       "      <td>54.1461</td>\n",
       "      <td>1.7665</td>\n",
       "      <td>71.0535</td>\n",
       "      <td>1.7271</td>\n",
       "      <td>0.4501</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>859.1656</td>\n",
       "      <td>3.6369</td>\n",
       "      <td>860.0016</td>\n",
       "      <td>0.5631</td>\n",
       "      <td>860.0000</td>\n",
       "      <td>0.3356</td>\n",
       "      <td>860.0012</td>\n",
       "      <td>0.3213</td>\n",
       "      <td>283.9833</td>\n",
       "      <td>9.5168</td>\n",
       "      <td>279.9868</td>\n",
       "      <td>6.6321</td>\n",
       "      <td>332.0135</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>332.3941</td>\n",
       "      <td>0.1251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>138982.5000</td>\n",
       "      <td>70.8809</td>\n",
       "      <td>3.8673</td>\n",
       "      <td>22.7144</td>\n",
       "      <td>3.8283</td>\n",
       "      <td>100.0167</td>\n",
       "      <td>0.5213</td>\n",
       "      <td>100.0367</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>69.2262</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>79.2494</td>\n",
       "      <td>27.6350</td>\n",
       "      <td>56.8676</td>\n",
       "      <td>3.2574</td>\n",
       "      <td>54.8648</td>\n",
       "      <td>1.9540</td>\n",
       "      <td>71.9600</td>\n",
       "      <td>1.9133</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>859.5508</td>\n",
       "      <td>4.5717</td>\n",
       "      <td>860.0107</td>\n",
       "      <td>0.6936</td>\n",
       "      <td>860.0057</td>\n",
       "      <td>0.3961</td>\n",
       "      <td>860.0064</td>\n",
       "      <td>0.3730</td>\n",
       "      <td>284.6139</td>\n",
       "      <td>9.6015</td>\n",
       "      <td>280.3895</td>\n",
       "      <td>6.8198</td>\n",
       "      <td>332.1073</td>\n",
       "      <td>0.1458</td>\n",
       "      <td>332.5807</td>\n",
       "      <td>0.1842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>148069.0000</td>\n",
       "      <td>74.4650</td>\n",
       "      <td>5.1421</td>\n",
       "      <td>31.3446</td>\n",
       "      <td>7.3669</td>\n",
       "      <td>100.1587</td>\n",
       "      <td>0.7584</td>\n",
       "      <td>100.2491</td>\n",
       "      <td>0.7515</td>\n",
       "      <td>70.1284</td>\n",
       "      <td>2.0272</td>\n",
       "      <td>94.0966</td>\n",
       "      <td>40.1163</td>\n",
       "      <td>59.3326</td>\n",
       "      <td>9.0297</td>\n",
       "      <td>57.8983</td>\n",
       "      <td>9.8082</td>\n",
       "      <td>74.3967</td>\n",
       "      <td>13.6354</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>860.8725</td>\n",
       "      <td>7.4406</td>\n",
       "      <td>860.1842</td>\n",
       "      <td>1.0168</td>\n",
       "      <td>860.3091</td>\n",
       "      <td>1.3156</td>\n",
       "      <td>860.7152</td>\n",
       "      <td>3.3884</td>\n",
       "      <td>286.4382</td>\n",
       "      <td>10.1586</td>\n",
       "      <td>287.5843</td>\n",
       "      <td>7.2423</td>\n",
       "      <td>332.2806</td>\n",
       "      <td>0.4863</td>\n",
       "      <td>332.8405</td>\n",
       "      <td>0.4634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               AN  DZ1_OP_AVG  DZ1_OP_Std  DZ2_OP_AVG  DZ2_OP_Std  \\\n",
       "count    136.0000    136.0000    136.0000    136.0000    136.0000   \n",
       "mean  128897.1912     69.9161      3.4442     20.7351      3.3756   \n",
       "std    12403.3939      1.9839      0.6989      3.6314      0.9315   \n",
       "min   102410.0000     62.9142      1.4303      4.3665      1.3248   \n",
       "25%   120467.7500     68.9546      2.9770     19.4396      2.6984   \n",
       "50%   130199.0000     69.8206      3.4286     21.2772      3.2869   \n",
       "75%   138982.5000     70.8809      3.8673     22.7144      3.8283   \n",
       "max   148069.0000     74.4650      5.1421     31.3446      7.3669   \n",
       "\n",
       "       DZ1_TEMP_AVG  DZ1_TEMP_Std  DZ2_TEMP_AVG  DZ2_TEMP_Std  CLEAN_AVG  \\\n",
       "count      136.0000      136.0000      136.0000      136.0000   136.0000   \n",
       "mean       100.0046        0.4568      100.0135        0.3719    67.7910   \n",
       "std          0.0620        0.1145        0.1091        0.1079     1.5089   \n",
       "min         99.3702        0.0786       98.8638        0.0464    64.6216   \n",
       "25%         99.9957        0.3819       99.9990        0.2865    66.5691   \n",
       "50%        100.0026        0.4446      100.0116        0.3697    67.8474   \n",
       "75%        100.0167        0.5213      100.0367        0.4444    69.2262   \n",
       "max        100.1587        0.7584      100.2491        0.7515    70.1284   \n",
       "\n",
       "       CLEAN_Std  HDZ1_OP_AVG  HDZ1_OP_Std  HDZ2_OP_AVG  HDZ2_OP_Std  \\\n",
       "count   136.0000     136.0000     136.0000     136.0000     136.0000   \n",
       "mean      0.6141      75.3717      24.7103      55.0219       2.7603   \n",
       "std       0.3317       6.3654       5.1960       3.3286       0.8542   \n",
       "min       0.0566      51.4322       2.5605      43.3118       0.9948   \n",
       "25%       0.3927      73.3242      22.1210      54.3702       2.2204   \n",
       "50%       0.5080      76.1939      24.7874      55.6828       2.7285   \n",
       "75%       0.7515      79.2494      27.6350      56.8676       3.2574   \n",
       "max       2.0272      94.0966      40.1163      59.3326       9.0297   \n",
       "\n",
       "       HDZ3_OP_AVG  HDZ3_OP_Std  HDZ4_OP_AVG  HDZ4_OP_Std  HDZ_CP_AVG  \\\n",
       "count     136.0000     136.0000     136.0000     136.0000    136.0000   \n",
       "mean       53.9568       1.8428      71.0287       1.8287      0.4479   \n",
       "std         1.7844       0.7529       1.4340       1.0587      0.0130   \n",
       "min        47.3185       0.9472      66.4568       0.9160      0.3411   \n",
       "25%        53.2812       1.5798      70.1344       1.6037      0.4500   \n",
       "50%        54.1461       1.7665      71.0535       1.7271      0.4501   \n",
       "75%        54.8648       1.9540      71.9600       1.9133      0.4502   \n",
       "max        57.8983       9.8082      74.3967      13.6354      0.4532   \n",
       "\n",
       "       HDZ_CP_Std  HDZ1_TEMP_AVG  HDZ1_TEMP_Std  HDZ2_TEMP_AVG  HDZ2_TEMP_Std  \\\n",
       "count    136.0000       136.0000       136.0000       136.0000       136.0000   \n",
       "mean       0.0076       859.1973         3.6437       860.0031         0.5663   \n",
       "std        0.0178         0.6014         1.3147         0.0259         0.1797   \n",
       "min        0.0013       856.5440         0.0971       859.8996         0.1591   \n",
       "25%        0.0029       858.8570         2.7201       859.9934         0.4257   \n",
       "50%        0.0036       859.1656         3.6369       860.0016         0.5631   \n",
       "75%        0.0046       859.5508         4.5717       860.0107         0.6936   \n",
       "max        0.1438       860.8725         7.4406       860.1842         1.0168   \n",
       "\n",
       "       HDZ3_TEMP_AVG  HDZ3_TEMP_Std  HDZ4_TEMP_AVG  HDZ4_TEMP_Std  \\\n",
       "count       136.0000       136.0000       136.0000       136.0000   \n",
       "mean        860.0051         0.3462       860.0074         0.3540   \n",
       "std           0.0365         0.1207         0.0659         0.2738   \n",
       "min         859.9213         0.1208       859.9477         0.0739   \n",
       "25%         859.9940         0.2698       859.9954         0.2923   \n",
       "50%         860.0000         0.3356       860.0012         0.3213   \n",
       "75%         860.0057         0.3961       860.0064         0.3730   \n",
       "max         860.3091         1.3156       860.7152         3.3884   \n",
       "\n",
       "       SCZ1_TEMP_AVG  SCZ1_TEMP_Std  SCZ2_TEMP_AVG  SCZ2_TEMP_Std  \\\n",
       "count       136.0000       136.0000       136.0000       136.0000   \n",
       "mean        284.0018         9.4269       280.0161         6.5432   \n",
       "std           0.7635         0.7131         0.8777         0.5733   \n",
       "min         280.9212         1.4632       277.5448         1.0366   \n",
       "25%         283.5871         9.3505       279.6242         6.3677   \n",
       "50%         283.9833         9.5168       279.9868         6.6321   \n",
       "75%         284.6139         9.6015       280.3895         6.8198   \n",
       "max         286.4382        10.1586       287.5843         7.2423   \n",
       "\n",
       "       STZ1_TEMP_AVG  STZ1_TEMP_Std  STZ2_TEMP_AVG  STZ2_TEMP_Std  \n",
       "count       136.0000       136.0000       136.0000       136.0000  \n",
       "mean        331.7992         0.1358       332.1629         0.1571  \n",
       "std           0.7910         0.0577         0.8774         0.0882  \n",
       "min         328.8319         0.0507       328.9242         0.0370  \n",
       "25%         331.9165         0.1012       332.1647         0.1017  \n",
       "50%         332.0135         0.1204       332.3941         0.1251  \n",
       "75%         332.1073         0.1458       332.5807         0.1842  \n",
       "max         332.2806         0.4863       332.8405         0.4634  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stand_A_02_01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4eb41d76-44d7-4e48-8f65-52851e5979d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>배정번호</th>\n",
       "      <th>양품수량</th>\n",
       "      <th>불량수량</th>\n",
       "      <th>총수량</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102410</td>\n",
       "      <td>15160</td>\n",
       "      <td>3</td>\n",
       "      <td>15163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     배정번호   양품수량  불량수량    총수량\n",
       "0  102410  15160     3  15163"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 퀄리티 데이터에서 불필요한 컬럼 삭제하기\n",
    "B_02 = B_01.copy()\n",
    "B_02.drop(['작업일', '공정명', '설비명'], axis=1, inplace=True)\n",
    "B_02.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "165d6871-d0bb-4cd3-9876-72ee6a62cd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN</th>\n",
       "      <th>GQ</th>\n",
       "      <th>BQ</th>\n",
       "      <th>TQ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102410</td>\n",
       "      <td>15160</td>\n",
       "      <td>3</td>\n",
       "      <td>15163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102585</td>\n",
       "      <td>29892</td>\n",
       "      <td>10</td>\n",
       "      <td>29902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102930</td>\n",
       "      <td>59616</td>\n",
       "      <td>30</td>\n",
       "      <td>59646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103142</td>\n",
       "      <td>74730</td>\n",
       "      <td>13</td>\n",
       "      <td>74743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103675</td>\n",
       "      <td>14979</td>\n",
       "      <td>2</td>\n",
       "      <td>14981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>147292</td>\n",
       "      <td>43765</td>\n",
       "      <td>12</td>\n",
       "      <td>43777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>147546</td>\n",
       "      <td>59957</td>\n",
       "      <td>16</td>\n",
       "      <td>59973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>147982</td>\n",
       "      <td>40981</td>\n",
       "      <td>12</td>\n",
       "      <td>40993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>147996</td>\n",
       "      <td>30239</td>\n",
       "      <td>9</td>\n",
       "      <td>30248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>148069</td>\n",
       "      <td>58778</td>\n",
       "      <td>0</td>\n",
       "      <td>58778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         AN     GQ  BQ     TQ\n",
       "0    102410  15160   3  15163\n",
       "1    102585  29892  10  29902\n",
       "2    102930  59616  30  59646\n",
       "3    103142  74730  13  74743\n",
       "4    103675  14979   2  14981\n",
       "..      ...    ...  ..    ...\n",
       "131  147292  43765  12  43777\n",
       "132  147546  59957  16  59973\n",
       "133  147982  40981  12  40993\n",
       "134  147996  30239   9  30248\n",
       "135  148069  58778   0  58778\n",
       "\n",
       "[136 rows x 4 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 퀄리티 데이터 컬럼명 변경\n",
    "Q_column_list = {\n",
    "    '배정번호': 'AN',\n",
    "    '양품수량': 'GQ',\n",
    "    '불량수량': 'BQ',\n",
    "    '총수량': 'TQ'\n",
    "}\n",
    "\n",
    "B_02.rename(columns=Q_column_list, inplace=True)\n",
    "B_02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b82a7-f5cc-41ef-aedb-2c17af1f3c91",
   "metadata": {},
   "source": [
    "### 03. Merge 후 데이터 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7d1894e-ef14-4aa0-8c57-3499ab334d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN</th>\n",
       "      <th>GQ</th>\n",
       "      <th>BQ</th>\n",
       "      <th>TQ</th>\n",
       "      <th>DZ1_OP_AVG</th>\n",
       "      <th>DZ1_OP_Std</th>\n",
       "      <th>DZ2_OP_AVG</th>\n",
       "      <th>DZ2_OP_Std</th>\n",
       "      <th>DZ1_TEMP_AVG</th>\n",
       "      <th>DZ1_TEMP_Std</th>\n",
       "      <th>DZ2_TEMP_AVG</th>\n",
       "      <th>DZ2_TEMP_Std</th>\n",
       "      <th>CLEAN_AVG</th>\n",
       "      <th>CLEAN_Std</th>\n",
       "      <th>HDZ1_OP_AVG</th>\n",
       "      <th>HDZ1_OP_Std</th>\n",
       "      <th>HDZ2_OP_AVG</th>\n",
       "      <th>HDZ2_OP_Std</th>\n",
       "      <th>HDZ3_OP_AVG</th>\n",
       "      <th>HDZ3_OP_Std</th>\n",
       "      <th>HDZ4_OP_AVG</th>\n",
       "      <th>HDZ4_OP_Std</th>\n",
       "      <th>HDZ_CP_AVG</th>\n",
       "      <th>HDZ_CP_Std</th>\n",
       "      <th>HDZ1_TEMP_AVG</th>\n",
       "      <th>HDZ1_TEMP_Std</th>\n",
       "      <th>HDZ2_TEMP_AVG</th>\n",
       "      <th>HDZ2_TEMP_Std</th>\n",
       "      <th>HDZ3_TEMP_AVG</th>\n",
       "      <th>HDZ3_TEMP_Std</th>\n",
       "      <th>HDZ4_TEMP_AVG</th>\n",
       "      <th>HDZ4_TEMP_Std</th>\n",
       "      <th>SCZ1_TEMP_AVG</th>\n",
       "      <th>SCZ1_TEMP_Std</th>\n",
       "      <th>SCZ2_TEMP_AVG</th>\n",
       "      <th>SCZ2_TEMP_Std</th>\n",
       "      <th>STZ1_TEMP_AVG</th>\n",
       "      <th>STZ1_TEMP_Std</th>\n",
       "      <th>STZ2_TEMP_AVG</th>\n",
       "      <th>STZ2_TEMP_Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102410</td>\n",
       "      <td>15160</td>\n",
       "      <td>3</td>\n",
       "      <td>15163</td>\n",
       "      <td>72.2527</td>\n",
       "      <td>3.6965</td>\n",
       "      <td>21.3545</td>\n",
       "      <td>4.3489</td>\n",
       "      <td>99.9435</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>100.0619</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>69.6026</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>75.7122</td>\n",
       "      <td>22.9797</td>\n",
       "      <td>59.3326</td>\n",
       "      <td>1.7839</td>\n",
       "      <td>50.6809</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>70.2494</td>\n",
       "      <td>2.5042</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>859.4869</td>\n",
       "      <td>3.5738</td>\n",
       "      <td>860.0124</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>860.0098</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>860.0106</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>282.5815</td>\n",
       "      <td>9.3711</td>\n",
       "      <td>280.1490</td>\n",
       "      <td>6.0339</td>\n",
       "      <td>329.0163</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>329.0709</td>\n",
       "      <td>0.1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102585</td>\n",
       "      <td>29892</td>\n",
       "      <td>10</td>\n",
       "      <td>29902</td>\n",
       "      <td>72.2356</td>\n",
       "      <td>3.3650</td>\n",
       "      <td>18.6026</td>\n",
       "      <td>2.8597</td>\n",
       "      <td>99.9874</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>100.0650</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>69.5912</td>\n",
       "      <td>1.0642</td>\n",
       "      <td>74.8979</td>\n",
       "      <td>23.4053</td>\n",
       "      <td>59.1689</td>\n",
       "      <td>1.9203</td>\n",
       "      <td>52.0143</td>\n",
       "      <td>1.4977</td>\n",
       "      <td>70.6397</td>\n",
       "      <td>2.2398</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>859.3333</td>\n",
       "      <td>3.0190</td>\n",
       "      <td>860.0086</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>859.9898</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>859.9918</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>282.7882</td>\n",
       "      <td>9.4996</td>\n",
       "      <td>279.7723</td>\n",
       "      <td>7.1615</td>\n",
       "      <td>328.9986</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>328.9242</td>\n",
       "      <td>0.0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102930</td>\n",
       "      <td>59616</td>\n",
       "      <td>30</td>\n",
       "      <td>59646</td>\n",
       "      <td>70.7202</td>\n",
       "      <td>3.2318</td>\n",
       "      <td>20.9119</td>\n",
       "      <td>2.5821</td>\n",
       "      <td>99.9956</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>100.0216</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>69.5295</td>\n",
       "      <td>1.0979</td>\n",
       "      <td>70.7003</td>\n",
       "      <td>23.6703</td>\n",
       "      <td>45.8490</td>\n",
       "      <td>2.1012</td>\n",
       "      <td>48.2632</td>\n",
       "      <td>1.4201</td>\n",
       "      <td>67.1299</td>\n",
       "      <td>2.1310</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>859.6424</td>\n",
       "      <td>2.8268</td>\n",
       "      <td>859.9879</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>859.9960</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>860.0075</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>283.3309</td>\n",
       "      <td>9.6804</td>\n",
       "      <td>279.3090</td>\n",
       "      <td>6.6652</td>\n",
       "      <td>329.1336</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>329.1488</td>\n",
       "      <td>0.1170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103142</td>\n",
       "      <td>74730</td>\n",
       "      <td>13</td>\n",
       "      <td>74743</td>\n",
       "      <td>72.4242</td>\n",
       "      <td>2.6352</td>\n",
       "      <td>22.2502</td>\n",
       "      <td>2.4028</td>\n",
       "      <td>100.0051</td>\n",
       "      <td>0.3314</td>\n",
       "      <td>100.0097</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>69.5369</td>\n",
       "      <td>1.0643</td>\n",
       "      <td>77.3254</td>\n",
       "      <td>15.4611</td>\n",
       "      <td>46.0317</td>\n",
       "      <td>1.5804</td>\n",
       "      <td>50.5714</td>\n",
       "      <td>1.2435</td>\n",
       "      <td>69.4428</td>\n",
       "      <td>1.7862</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>859.8549</td>\n",
       "      <td>1.5416</td>\n",
       "      <td>859.9955</td>\n",
       "      <td>0.2466</td>\n",
       "      <td>859.9969</td>\n",
       "      <td>0.1886</td>\n",
       "      <td>860.0035</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>282.8823</td>\n",
       "      <td>9.4955</td>\n",
       "      <td>279.2411</td>\n",
       "      <td>6.5374</td>\n",
       "      <td>329.0821</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>329.0732</td>\n",
       "      <td>0.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103675</td>\n",
       "      <td>14979</td>\n",
       "      <td>2</td>\n",
       "      <td>14981</td>\n",
       "      <td>72.7746</td>\n",
       "      <td>4.1592</td>\n",
       "      <td>21.8652</td>\n",
       "      <td>3.6228</td>\n",
       "      <td>99.9835</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>100.0437</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>69.3210</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>74.7738</td>\n",
       "      <td>23.5540</td>\n",
       "      <td>45.1690</td>\n",
       "      <td>1.5090</td>\n",
       "      <td>50.2557</td>\n",
       "      <td>1.7672</td>\n",
       "      <td>69.7685</td>\n",
       "      <td>2.7004</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>859.8177</td>\n",
       "      <td>3.6836</td>\n",
       "      <td>859.9567</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>860.0242</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>860.0072</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>283.5816</td>\n",
       "      <td>9.7056</td>\n",
       "      <td>277.5448</td>\n",
       "      <td>5.3659</td>\n",
       "      <td>329.0109</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>329.1145</td>\n",
       "      <td>0.0879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AN     GQ  BQ     TQ  DZ1_OP_AVG  DZ1_OP_Std  DZ2_OP_AVG  DZ2_OP_Std  \\\n",
       "0  102410  15160   3  15163     72.2527      3.6965     21.3545      4.3489   \n",
       "1  102585  29892  10  29902     72.2356      3.3650     18.6026      2.8597   \n",
       "2  102930  59616  30  59646     70.7202      3.2318     20.9119      2.5821   \n",
       "3  103142  74730  13  74743     72.4242      2.6352     22.2502      2.4028   \n",
       "4  103675  14979   2  14981     72.7746      4.1592     21.8652      3.6228   \n",
       "\n",
       "   DZ1_TEMP_AVG  DZ1_TEMP_Std  DZ2_TEMP_AVG  DZ2_TEMP_Std  CLEAN_AVG  \\\n",
       "0       99.9435        0.5939      100.0619        0.4835    69.6026   \n",
       "1       99.9874        0.5154      100.0650        0.3561    69.5912   \n",
       "2       99.9956        0.4727      100.0216        0.3430    69.5295   \n",
       "3      100.0051        0.3314      100.0097        0.2518    69.5369   \n",
       "4       99.9835        0.6553      100.0437        0.4707    69.3210   \n",
       "\n",
       "   CLEAN_Std  HDZ1_OP_AVG  HDZ1_OP_Std  HDZ2_OP_AVG  HDZ2_OP_Std  HDZ3_OP_AVG  \\\n",
       "0     0.8454      75.7122      22.9797      59.3326       1.7839      50.6809   \n",
       "1     1.0642      74.8979      23.4053      59.1689       1.9203      52.0143   \n",
       "2     1.0979      70.7003      23.6703      45.8490       2.1012      48.2632   \n",
       "3     1.0643      77.3254      15.4611      46.0317       1.5804      50.5714   \n",
       "4     0.9917      74.7738      23.5540      45.1690       1.5090      50.2557   \n",
       "\n",
       "   HDZ3_OP_Std  HDZ4_OP_AVG  HDZ4_OP_Std  HDZ_CP_AVG  HDZ_CP_Std  \\\n",
       "0       1.4400      70.2494       2.5042      0.4505      0.0059   \n",
       "1       1.4977      70.6397       2.2398      0.4502      0.0028   \n",
       "2       1.4201      67.1299       2.1310      0.4493      0.0059   \n",
       "3       1.2435      69.4428       1.7862      0.4498      0.0040   \n",
       "4       1.7672      69.7685       2.7004      0.4500      0.0030   \n",
       "\n",
       "   HDZ1_TEMP_AVG  HDZ1_TEMP_Std  HDZ2_TEMP_AVG  HDZ2_TEMP_Std  HDZ3_TEMP_AVG  \\\n",
       "0       859.4869         3.5738       860.0124         0.4007       860.0098   \n",
       "1       859.3333         3.0190       860.0086         0.4035       859.9898   \n",
       "2       859.6424         2.8268       859.9879         0.3844       859.9960   \n",
       "3       859.8549         1.5416       859.9955         0.2466       859.9969   \n",
       "4       859.8177         3.6836       859.9567         0.2956       860.0242   \n",
       "\n",
       "   HDZ3_TEMP_Std  HDZ4_TEMP_AVG  HDZ4_TEMP_Std  SCZ1_TEMP_AVG  SCZ1_TEMP_Std  \\\n",
       "0         0.2816       860.0106         0.5534       282.5815         9.3711   \n",
       "1         0.2411       859.9918         0.4805       282.7882         9.4996   \n",
       "2         0.2419       860.0075         0.4184       283.3309         9.6804   \n",
       "3         0.1886       860.0035         0.2967       282.8823         9.4955   \n",
       "4         0.3190       860.0072         0.5712       283.5816         9.7056   \n",
       "\n",
       "   SCZ2_TEMP_AVG  SCZ2_TEMP_Std  STZ1_TEMP_AVG  STZ1_TEMP_Std  STZ2_TEMP_AVG  \\\n",
       "0       280.1490         6.0339       329.0163         0.1270       329.0709   \n",
       "1       279.7723         7.1615       328.9986         0.1012       328.9242   \n",
       "2       279.3090         6.6652       329.1336         0.1212       329.1488   \n",
       "3       279.2411         6.5374       329.0821         0.1000       329.0732   \n",
       "4       277.5448         5.3659       329.0109         0.0967       329.1145   \n",
       "\n",
       "   STZ2_TEMP_Std  \n",
       "0         0.1220  \n",
       "1         0.0891  \n",
       "2         0.1170  \n",
       "3         0.1020  \n",
       "4         0.0879  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left join으로 퀄리티, 공정 데이터를 결합\n",
    "Standard_Total = pd.merge(B_02, Stand_A_02_01, on='AN', how='left')\n",
    "Standard_Total.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e154597-0ff8-4392-9b58-4bf872222c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AN</th>\n",
       "      <th>GQ</th>\n",
       "      <th>BQ</th>\n",
       "      <th>TQ</th>\n",
       "      <th>DZ1_OP_AVG</th>\n",
       "      <th>DZ1_OP_Std</th>\n",
       "      <th>DZ2_OP_AVG</th>\n",
       "      <th>DZ2_OP_Std</th>\n",
       "      <th>DZ1_TEMP_AVG</th>\n",
       "      <th>DZ1_TEMP_Std</th>\n",
       "      <th>DZ2_TEMP_AVG</th>\n",
       "      <th>DZ2_TEMP_Std</th>\n",
       "      <th>CLEAN_AVG</th>\n",
       "      <th>CLEAN_Std</th>\n",
       "      <th>HDZ1_OP_AVG</th>\n",
       "      <th>HDZ1_OP_Std</th>\n",
       "      <th>HDZ2_OP_AVG</th>\n",
       "      <th>HDZ2_OP_Std</th>\n",
       "      <th>HDZ3_OP_AVG</th>\n",
       "      <th>HDZ3_OP_Std</th>\n",
       "      <th>HDZ4_OP_AVG</th>\n",
       "      <th>HDZ4_OP_Std</th>\n",
       "      <th>HDZ_CP_AVG</th>\n",
       "      <th>HDZ_CP_Std</th>\n",
       "      <th>HDZ1_TEMP_AVG</th>\n",
       "      <th>HDZ1_TEMP_Std</th>\n",
       "      <th>HDZ2_TEMP_AVG</th>\n",
       "      <th>HDZ2_TEMP_Std</th>\n",
       "      <th>HDZ3_TEMP_AVG</th>\n",
       "      <th>HDZ3_TEMP_Std</th>\n",
       "      <th>HDZ4_TEMP_AVG</th>\n",
       "      <th>HDZ4_TEMP_Std</th>\n",
       "      <th>SCZ1_TEMP_AVG</th>\n",
       "      <th>SCZ1_TEMP_Std</th>\n",
       "      <th>SCZ2_TEMP_AVG</th>\n",
       "      <th>SCZ2_TEMP_Std</th>\n",
       "      <th>STZ1_TEMP_AVG</th>\n",
       "      <th>STZ1_TEMP_Std</th>\n",
       "      <th>STZ2_TEMP_AVG</th>\n",
       "      <th>STZ2_TEMP_Std</th>\n",
       "      <th>BQ Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>102410</td>\n",
       "      <td>15160</td>\n",
       "      <td>3</td>\n",
       "      <td>15163</td>\n",
       "      <td>72.2527</td>\n",
       "      <td>3.6965</td>\n",
       "      <td>21.3545</td>\n",
       "      <td>4.3489</td>\n",
       "      <td>99.9435</td>\n",
       "      <td>0.5939</td>\n",
       "      <td>100.0619</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>69.6026</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>75.7122</td>\n",
       "      <td>22.9797</td>\n",
       "      <td>59.3326</td>\n",
       "      <td>1.7839</td>\n",
       "      <td>50.6809</td>\n",
       "      <td>1.4400</td>\n",
       "      <td>70.2494</td>\n",
       "      <td>2.5042</td>\n",
       "      <td>0.4505</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>859.4869</td>\n",
       "      <td>3.5738</td>\n",
       "      <td>860.0124</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>860.0098</td>\n",
       "      <td>0.2816</td>\n",
       "      <td>860.0106</td>\n",
       "      <td>0.5534</td>\n",
       "      <td>282.5815</td>\n",
       "      <td>9.3711</td>\n",
       "      <td>280.1490</td>\n",
       "      <td>6.0339</td>\n",
       "      <td>329.0163</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>329.0709</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102585</td>\n",
       "      <td>29892</td>\n",
       "      <td>10</td>\n",
       "      <td>29902</td>\n",
       "      <td>72.2356</td>\n",
       "      <td>3.3650</td>\n",
       "      <td>18.6026</td>\n",
       "      <td>2.8597</td>\n",
       "      <td>99.9874</td>\n",
       "      <td>0.5154</td>\n",
       "      <td>100.0650</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>69.5912</td>\n",
       "      <td>1.0642</td>\n",
       "      <td>74.8979</td>\n",
       "      <td>23.4053</td>\n",
       "      <td>59.1689</td>\n",
       "      <td>1.9203</td>\n",
       "      <td>52.0143</td>\n",
       "      <td>1.4977</td>\n",
       "      <td>70.6397</td>\n",
       "      <td>2.2398</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>859.3333</td>\n",
       "      <td>3.0190</td>\n",
       "      <td>860.0086</td>\n",
       "      <td>0.4035</td>\n",
       "      <td>859.9898</td>\n",
       "      <td>0.2411</td>\n",
       "      <td>859.9918</td>\n",
       "      <td>0.4805</td>\n",
       "      <td>282.7882</td>\n",
       "      <td>9.4996</td>\n",
       "      <td>279.7723</td>\n",
       "      <td>7.1615</td>\n",
       "      <td>328.9986</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>328.9242</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>0.0330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102930</td>\n",
       "      <td>59616</td>\n",
       "      <td>30</td>\n",
       "      <td>59646</td>\n",
       "      <td>70.7202</td>\n",
       "      <td>3.2318</td>\n",
       "      <td>20.9119</td>\n",
       "      <td>2.5821</td>\n",
       "      <td>99.9956</td>\n",
       "      <td>0.4727</td>\n",
       "      <td>100.0216</td>\n",
       "      <td>0.3430</td>\n",
       "      <td>69.5295</td>\n",
       "      <td>1.0979</td>\n",
       "      <td>70.7003</td>\n",
       "      <td>23.6703</td>\n",
       "      <td>45.8490</td>\n",
       "      <td>2.1012</td>\n",
       "      <td>48.2632</td>\n",
       "      <td>1.4201</td>\n",
       "      <td>67.1299</td>\n",
       "      <td>2.1310</td>\n",
       "      <td>0.4493</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>859.6424</td>\n",
       "      <td>2.8268</td>\n",
       "      <td>859.9879</td>\n",
       "      <td>0.3844</td>\n",
       "      <td>859.9960</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>860.0075</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>283.3309</td>\n",
       "      <td>9.6804</td>\n",
       "      <td>279.3090</td>\n",
       "      <td>6.6652</td>\n",
       "      <td>329.1336</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>329.1488</td>\n",
       "      <td>0.1170</td>\n",
       "      <td>0.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103142</td>\n",
       "      <td>74730</td>\n",
       "      <td>13</td>\n",
       "      <td>74743</td>\n",
       "      <td>72.4242</td>\n",
       "      <td>2.6352</td>\n",
       "      <td>22.2502</td>\n",
       "      <td>2.4028</td>\n",
       "      <td>100.0051</td>\n",
       "      <td>0.3314</td>\n",
       "      <td>100.0097</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>69.5369</td>\n",
       "      <td>1.0643</td>\n",
       "      <td>77.3254</td>\n",
       "      <td>15.4611</td>\n",
       "      <td>46.0317</td>\n",
       "      <td>1.5804</td>\n",
       "      <td>50.5714</td>\n",
       "      <td>1.2435</td>\n",
       "      <td>69.4428</td>\n",
       "      <td>1.7862</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>859.8549</td>\n",
       "      <td>1.5416</td>\n",
       "      <td>859.9955</td>\n",
       "      <td>0.2466</td>\n",
       "      <td>859.9969</td>\n",
       "      <td>0.1886</td>\n",
       "      <td>860.0035</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>282.8823</td>\n",
       "      <td>9.4955</td>\n",
       "      <td>279.2411</td>\n",
       "      <td>6.5374</td>\n",
       "      <td>329.0821</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>329.0732</td>\n",
       "      <td>0.1020</td>\n",
       "      <td>0.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>103675</td>\n",
       "      <td>14979</td>\n",
       "      <td>2</td>\n",
       "      <td>14981</td>\n",
       "      <td>72.7746</td>\n",
       "      <td>4.1592</td>\n",
       "      <td>21.8652</td>\n",
       "      <td>3.6228</td>\n",
       "      <td>99.9835</td>\n",
       "      <td>0.6553</td>\n",
       "      <td>100.0437</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>69.3210</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>74.7738</td>\n",
       "      <td>23.5540</td>\n",
       "      <td>45.1690</td>\n",
       "      <td>1.5090</td>\n",
       "      <td>50.2557</td>\n",
       "      <td>1.7672</td>\n",
       "      <td>69.7685</td>\n",
       "      <td>2.7004</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>859.8177</td>\n",
       "      <td>3.6836</td>\n",
       "      <td>859.9567</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>860.0242</td>\n",
       "      <td>0.3190</td>\n",
       "      <td>860.0072</td>\n",
       "      <td>0.5712</td>\n",
       "      <td>283.5816</td>\n",
       "      <td>9.7056</td>\n",
       "      <td>277.5448</td>\n",
       "      <td>5.3659</td>\n",
       "      <td>329.0109</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>329.1145</td>\n",
       "      <td>0.0879</td>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AN     GQ  BQ     TQ  DZ1_OP_AVG  DZ1_OP_Std  DZ2_OP_AVG  DZ2_OP_Std  \\\n",
       "0  102410  15160   3  15163     72.2527      3.6965     21.3545      4.3489   \n",
       "1  102585  29892  10  29902     72.2356      3.3650     18.6026      2.8597   \n",
       "2  102930  59616  30  59646     70.7202      3.2318     20.9119      2.5821   \n",
       "3  103142  74730  13  74743     72.4242      2.6352     22.2502      2.4028   \n",
       "4  103675  14979   2  14981     72.7746      4.1592     21.8652      3.6228   \n",
       "\n",
       "   DZ1_TEMP_AVG  DZ1_TEMP_Std  DZ2_TEMP_AVG  DZ2_TEMP_Std  CLEAN_AVG  \\\n",
       "0       99.9435        0.5939      100.0619        0.4835    69.6026   \n",
       "1       99.9874        0.5154      100.0650        0.3561    69.5912   \n",
       "2       99.9956        0.4727      100.0216        0.3430    69.5295   \n",
       "3      100.0051        0.3314      100.0097        0.2518    69.5369   \n",
       "4       99.9835        0.6553      100.0437        0.4707    69.3210   \n",
       "\n",
       "   CLEAN_Std  HDZ1_OP_AVG  HDZ1_OP_Std  HDZ2_OP_AVG  HDZ2_OP_Std  HDZ3_OP_AVG  \\\n",
       "0     0.8454      75.7122      22.9797      59.3326       1.7839      50.6809   \n",
       "1     1.0642      74.8979      23.4053      59.1689       1.9203      52.0143   \n",
       "2     1.0979      70.7003      23.6703      45.8490       2.1012      48.2632   \n",
       "3     1.0643      77.3254      15.4611      46.0317       1.5804      50.5714   \n",
       "4     0.9917      74.7738      23.5540      45.1690       1.5090      50.2557   \n",
       "\n",
       "   HDZ3_OP_Std  HDZ4_OP_AVG  HDZ4_OP_Std  HDZ_CP_AVG  HDZ_CP_Std  \\\n",
       "0       1.4400      70.2494       2.5042      0.4505      0.0059   \n",
       "1       1.4977      70.6397       2.2398      0.4502      0.0028   \n",
       "2       1.4201      67.1299       2.1310      0.4493      0.0059   \n",
       "3       1.2435      69.4428       1.7862      0.4498      0.0040   \n",
       "4       1.7672      69.7685       2.7004      0.4500      0.0030   \n",
       "\n",
       "   HDZ1_TEMP_AVG  HDZ1_TEMP_Std  HDZ2_TEMP_AVG  HDZ2_TEMP_Std  HDZ3_TEMP_AVG  \\\n",
       "0       859.4869         3.5738       860.0124         0.4007       860.0098   \n",
       "1       859.3333         3.0190       860.0086         0.4035       859.9898   \n",
       "2       859.6424         2.8268       859.9879         0.3844       859.9960   \n",
       "3       859.8549         1.5416       859.9955         0.2466       859.9969   \n",
       "4       859.8177         3.6836       859.9567         0.2956       860.0242   \n",
       "\n",
       "   HDZ3_TEMP_Std  HDZ4_TEMP_AVG  HDZ4_TEMP_Std  SCZ1_TEMP_AVG  SCZ1_TEMP_Std  \\\n",
       "0         0.2816       860.0106         0.5534       282.5815         9.3711   \n",
       "1         0.2411       859.9918         0.4805       282.7882         9.4996   \n",
       "2         0.2419       860.0075         0.4184       283.3309         9.6804   \n",
       "3         0.1886       860.0035         0.2967       282.8823         9.4955   \n",
       "4         0.3190       860.0072         0.5712       283.5816         9.7056   \n",
       "\n",
       "   SCZ2_TEMP_AVG  SCZ2_TEMP_Std  STZ1_TEMP_AVG  STZ1_TEMP_Std  STZ2_TEMP_AVG  \\\n",
       "0       280.1490         6.0339       329.0163         0.1270       329.0709   \n",
       "1       279.7723         7.1615       328.9986         0.1012       328.9242   \n",
       "2       279.3090         6.6652       329.1336         0.1212       329.1488   \n",
       "3       279.2411         6.5374       329.0821         0.1000       329.0732   \n",
       "4       277.5448         5.3659       329.0109         0.0967       329.1145   \n",
       "\n",
       "   STZ2_TEMP_Std  BQ Rate  \n",
       "0         0.1220   0.0200  \n",
       "1         0.0891   0.0330  \n",
       "2         0.1170   0.0500  \n",
       "3         0.1020   0.0170  \n",
       "4         0.0879   0.0130  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 종속변수를 만들기 위해 불량 수량 / 총 생산량 * 100을 통해 불량률 컬럼 생성\n",
    "Standard_Total['BQ Rate'] = round(Standard_Total['BQ'] / Standard_Total['TQ'] * 100, 3)\n",
    "Standard_Total.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95a7551f-cd0e-416a-bf39-33000089bc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   136.0000\n",
       "mean      0.0370\n",
       "std       0.0482\n",
       "min       0.0000\n",
       "25%       0.0128\n",
       "50%       0.0220\n",
       "75%       0.0460\n",
       "max       0.3690\n",
       "Name: BQ Rate, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공정이 안전한지 위험한지 판단하기 위해 3사분위수를 기준으로 판단하자\n",
    "Standard_Total['BQ Rate'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5112da6-a2fc-4f6a-87b7-bb1b8813434c",
   "metadata": {},
   "source": [
    "#### 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42f96c3f-6dff-47ac-b101-bc4ce7deafe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total_heatmap = Standard_Total.copy()\n",
    "\n",
    "# def plot_correlation_heatmap(df):\n",
    "#     # 데이터프레임의 상관계수 행렬을 계산\n",
    "#     corr = df.corr()\n",
    "\n",
    "#     # 상관계수 행렬의 절대값을 기준으로 내림차순 정렬\n",
    "#     cols = corr.abs().sum().sort_values(ascending=False).index\n",
    "\n",
    "#     # 정렬된 순서대로 상관계수 행렬 재배열\n",
    "#     sorted_corr = corr.loc[cols, cols]\n",
    "\n",
    "#     # 히트맵 그리기\n",
    "#     plt.figure(figsize=(15, 15), dpi=600)\n",
    "#     sns.heatmap(sorted_corr, annot=True, cmap='coolwarm', vmin=-1, vmax=1, linewidths=0.5, annot_kws={'size': 6})\n",
    "    \n",
    "#     # x, y 축의 텍스트 크기 조절\n",
    "#     plt.xticks(fontsize=8)\n",
    "#     plt.yticks(fontsize=8)\n",
    "#     plt.title(\"Feature Correlation Heatmap\")\n",
    "#     plt.show()\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plot_correlation_heatmap(Total_heatmap.drop(['AN', 'GQ', 'BQ', 'TQ'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bca9d99d-b7a6-4d80-b384-cdca5042c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defective Stage: 불량 단계\n",
    "# 'BQ Rate' 컬럼의 값이 0.46보다 크거나 같으면 1, 작으면 0을 'DS' 컬럼에 할당\n",
    "Standard_Total['DS'] = np.where(Standard_Total['BQ Rate'] >= 0.046, '위험', '안전')\n",
    "\n",
    "# 불량단계 안전 0은 101개, 위험 1은 35개 배정번호에서 일어났다.\n",
    "Standard_Total['DS'].value_counts()\n",
    "\n",
    "# 필요없는 컬럼 삭제\n",
    "Standard_Total.drop(['AN', 'GQ', 'BQ', 'TQ', 'BQ Rate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff309cc-bc9a-46c6-8017-57ff8d3be52d",
   "metadata": {},
   "source": [
    "### 04. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b66297d2-b57e-48c1-b2d7-c71bf31b0b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          안전       0.76      0.95      0.84        20\n",
      "          위험       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.71      0.60      0.60        28\n",
      "weighted avg       0.73      0.75      0.71        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# dataset\n",
    "X = Standard_Total.drop('DS', axis=1)\n",
    "y = Standard_Total['DS']  # Binary classification: Setosa vs. non-Setosa\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a machine learning pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Step 1: Feature Scaling\n",
    "    ('feature_selector', RFECV(estimator=RandomForestClassifier(n_estimators=100, random_state=42), cv=5)),  # Step 2: Feature Selection with RFECV\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Step 3: Classification\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "add540c5-7d17-49aa-9c48-a8b2ff8f51b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: VarianceThreshold, Model: SVM\n",
      "Accuracy: 0.71\n",
      "AUC: 0.50\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        20\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.36      0.50      0.42        28\n",
      "weighted avg       0.51      0.71      0.60        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: VarianceThreshold, Model: K-NN\n",
      "Accuracy: 0.64\n",
      "AUC: 0.49\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        20\n",
      "           1       0.25      0.12      0.17         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.48      0.49      0.47        28\n",
      "weighted avg       0.58      0.64      0.60        28\n",
      "\n",
      "==================================================\n",
      "[06:05:18] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: VarianceThreshold, Model: XGBoost\n",
      "Accuracy: 0.71\n",
      "AUC: 0.57\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82        20\n",
      "           1       0.50      0.25      0.33         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.62      0.57      0.58        28\n",
      "weighted avg       0.68      0.71      0.68        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: VarianceThreshold, Model: LightGBM\n",
      "Accuracy: 0.64\n",
      "AUC: 0.56\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75        20\n",
      "           1       0.38      0.38      0.38         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.56      0.56      0.56        28\n",
      "weighted avg       0.64      0.64      0.64        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: SelectKBest, Model: SVM\n",
      "Accuracy: 0.71\n",
      "AUC: 0.50\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        20\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.36      0.50      0.42        28\n",
      "weighted avg       0.51      0.71      0.60        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: SelectKBest, Model: K-NN\n",
      "Accuracy: 0.68\n",
      "AUC: 0.51\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.90      0.80        20\n",
      "           1       0.33      0.12      0.18         8\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.53      0.51      0.49        28\n",
      "weighted avg       0.61      0.68      0.62        28\n",
      "\n",
      "==================================================\n",
      "[06:05:28] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: SelectKBest, Model: XGBoost\n",
      "Accuracy: 0.61\n",
      "AUC: 0.50\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        20\n",
      "           1       0.29      0.25      0.27         8\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.50      0.50      0.50        28\n",
      "weighted avg       0.59      0.61      0.60        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: SelectKBest, Model: LightGBM\n",
      "Accuracy: 0.68\n",
      "AUC: 0.55\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79        20\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.57      0.55      0.55        28\n",
      "weighted avg       0.64      0.68      0.65        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: SelectFromModel, Model: SVM\n",
      "Accuracy: 0.71\n",
      "AUC: 0.50\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        20\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.36      0.50      0.42        28\n",
      "weighted avg       0.51      0.71      0.60        28\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: SelectFromModel, Model: K-NN\n",
      "Accuracy: 0.64\n",
      "AUC: 0.49\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        20\n",
      "           1       0.25      0.12      0.17         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.48      0.49      0.47        28\n",
      "weighted avg       0.58      0.64      0.60        28\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:05:39] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: SelectFromModel, Model: XGBoost\n",
      "Accuracy: 0.75\n",
      "AUC: 0.60\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84        20\n",
      "           1       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.71      0.60      0.60        28\n",
      "weighted avg       0.73      0.75      0.71        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: SelectFromModel, Model: LightGBM\n",
      "Accuracy: 0.71\n",
      "AUC: 0.61\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.85      0.81        20\n",
      "           1       0.50      0.38      0.43         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.64      0.61      0.62        28\n",
      "weighted avg       0.69      0.71      0.70        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: RFECV, Model: SVM\n",
      "Accuracy: 0.75\n",
      "AUC: 0.56\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        20\n",
      "           1       1.00      0.12      0.22         8\n",
      "\n",
      "    accuracy                           0.75        28\n",
      "   macro avg       0.87      0.56      0.54        28\n",
      "weighted avg       0.81      0.75      0.67        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: RFECV, Model: K-NN\n",
      "Accuracy: 0.61\n",
      "AUC: 0.46\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74        20\n",
      "           1       0.20      0.12      0.15         8\n",
      "\n",
      "    accuracy                           0.61        28\n",
      "   macro avg       0.45      0.46      0.45        28\n",
      "weighted avg       0.55      0.61      0.58        28\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:07:03] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: RFECV, Model: XGBoost\n",
      "Accuracy: 0.64\n",
      "AUC: 0.49\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        20\n",
      "           1       0.25      0.12      0.17         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.48      0.49      0.47        28\n",
      "weighted avg       0.58      0.64      0.60        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: RFECV, Model: LightGBM\n",
      "Accuracy: 0.64\n",
      "AUC: 0.49\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        20\n",
      "           1       0.25      0.12      0.17         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.48      0.49      0.47        28\n",
      "weighted avg       0.58      0.64      0.60        28\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: SFS, Model: SVM\n",
      "Accuracy: 0.71\n",
      "AUC: 0.50\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        20\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.36      0.50      0.42        28\n",
      "weighted avg       0.51      0.71      0.60        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: SFS, Model: K-NN\n",
      "Accuracy: 0.64\n",
      "AUC: 0.53\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        20\n",
      "           1       0.33      0.25      0.29         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.53      0.53      0.52        28\n",
      "weighted avg       0.61      0.64      0.63        28\n",
      "\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[06:12:15] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/xgboost/data.py:112: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable Selection Method: SFS, Model: XGBoost\n",
      "Accuracy: 0.64\n",
      "AUC: 0.53\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        20\n",
      "           1       0.33      0.25      0.29         8\n",
      "\n",
      "    accuracy                           0.64        28\n",
      "   macro avg       0.53      0.53      0.52        28\n",
      "weighted avg       0.61      0.64      0.63        28\n",
      "\n",
      "==================================================\n",
      "Variable Selection Method: SFS, Model: LightGBM\n",
      "Accuracy: 0.68\n",
      "AUC: 0.55\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79        20\n",
      "           1       0.40      0.25      0.31         8\n",
      "\n",
      "    accuracy                           0.68        28\n",
      "   macro avg       0.57      0.55      0.55        28\n",
      "weighted avg       0.64      0.68      0.65        28\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, SelectPercentile, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a list of variable selection methods and models\n",
    "variable_selection_methods = [\n",
    "    ('VarianceThreshold', VarianceThreshold()),\n",
    "    ('SelectKBest', SelectKBest(k=5)),\n",
    "    ('SelectFromModel', SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42))),\n",
    "    ('RFECV', RFECV(estimator=RandomForestClassifier(n_estimators=100, random_state=42), cv=5)),\n",
    "    ('SFS', SequentialFeatureSelector(RandomForestClassifier(n_estimators=100, random_state=42), k_features=5, forward=True, floating=False, verbose=0, scoring='accuracy'))\n",
    "]\n",
    "\n",
    "models = [\n",
    "    ('SVM', SVC()),\n",
    "    ('K-NN', KNeighborsClassifier()),\n",
    "    ('XGBoost', XGBClassifier()),\n",
    "    ('LightGBM', LGBMClassifier())\n",
    "]\n",
    "\n",
    "# dataset\n",
    "X = Standard_Total.drop('DS', axis=1)\n",
    "y = Standard_Total['DS']  # Binary classification: Setosa vs. non-Setosa\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Iterate through variable selection methods and models\n",
    "for method_name, method in variable_selection_methods:\n",
    "    for model_name, model in models:\n",
    "        # Create a machine learning pipeline\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),  # Step 1: Feature Scaling\n",
    "            ('feature_selector', method),  # Step 2: Feature Selection\n",
    "            ('classifier', model)  # Step 3: Classification\n",
    "        ])\n",
    "\n",
    "        # Fit the pipeline on the training data\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "\n",
    "        # Evaluate the model\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_pred)\n",
    "        classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "        print(f\"Variable Selection Method: {method_name}, Model: {model_name}\")\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "        print(f\"AUC: {auc:.2f}\")\n",
    "        print(\"Classification Report:\\n\", classification_rep)\n",
    "        print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae688743-039c-40c1-8f61-aa7ef7aa86bb",
   "metadata": {},
   "source": [
    "### 04. 데이터 정규화 및 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e19fcbc0-1716-46c8-bc20-5462d7b2201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라벨 인코더를 이용해 종속변수를 수치 범주 데이터 0과 1로 변환 전처리\n",
    "X_num = Standard_Total.drop(columns=['DS'])\n",
    "y = Standard_Total['DS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0287b9bf-2919-471e-8d93-b57e479e20cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['안전' '위험']\n"
     ]
    }
   ],
   "source": [
    "# 라벨 인코더를 이용해 종속변수를 수치 범주 데이터 0과 1로 변환\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ba1455-fcfb-4123-b2f3-75ece70f6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 학습 데이터(80%)와 테스트 데이터(20%)로 분리\n",
    "X_train_select, X_test_select, y_train_select, y_test_select = train_test_split(X_num, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dac9ea-0daf-435d-a764-c25fb4a84755",
   "metadata": {},
   "source": [
    "#### 04-01. StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d835f64-a566-4479-9935-a559c2f6d312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 데이터 정규화\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # StandardScaler 초기화(생성)\n",
    "# S_scaler = StandardScaler()\n",
    "\n",
    "# # 학습 데이터 스케일링\n",
    "# X_train_scaled = S_scaler.fit_transform(X_train_select)\n",
    "\n",
    "# # 테스트 데이터의 스케일링\n",
    "# X_test_scaled = S_scaler.transform(X_test_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd97d86-4daa-4a3b-a9bc-2e4d65aa7064",
   "metadata": {},
   "source": [
    "#### 04-02. RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "492687f2-7f9b-4377-b191-bca6b5b25106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 정규화\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# RobustScaler 초기화(생성)\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# 학습 데이터 스케일링\n",
    "X_train_scaled = scaler.fit_transform(X_train_select)\n",
    "\n",
    "# 테스트 데이터의 스케일링\n",
    "X_test_scaled = scaler.transform(X_test_select)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c78a8bb-0e6a-4392-b508-b991e528b9a4",
   "metadata": {},
   "source": [
    "#### Recursive Feature Elimination with Cross-Validation(RFECV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "660acc15-5b15-4e82-8950-cf00aeed01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 16 features.\n",
      "불량단계 예측 사용 변수 목록: ['DZ1_TEMP_Std', 'DZ2_TEMP_AVG', 'HDZ1_OP_AVG', 'HDZ1_OP_Std', 'HDZ3_OP_AVG', 'HDZ4_OP_Std', 'HDZ1_TEMP_AVG', 'HDZ4_TEMP_Std', 'SCZ1_TEMP_AVG', 'SCZ2_TEMP_AVG', 'SCZ2_TEMP_Std', 'STZ1_TEMP_Std']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "rfe_selector = RFE(estimator=XGBClassifier(eval_metric='error')\n",
    "                   , n_features_to_select=12\n",
    "                   , step=10\n",
    "                   , verbose=5)\n",
    "rfe_selector.fit(X_train_select, y_train_select)\n",
    "rfe_support = rfe_selector.get_support()\n",
    "rfe_feature = X_num.loc[:,rfe_support].columns.tolist()\n",
    "\n",
    "print(f'불량단계 예측 사용 변수 목록: {rfe_feature}')\n",
    "\n",
    "# # RFE to RFECV\n",
    "# # step 10 to 2\n",
    "# from sklearn.feature_selection import RFECV\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # RFECV 객체 생성\n",
    "# rfe_selector = RFECV(\n",
    "#     estimator=XGBClassifier(eval_metric='error', n_estimators=100, max_depth=3, learning_rate=0.01),  # 기본 분류기, XGBoost 분류기 사용\n",
    "#     step=2,  # 각 반복에서 제거할 피처의 수. 정수로 지정하면 해당 수만큼 피처를 제거, 0과 1 사이의 실수로 지정하면 해당 비율만큼 피처를 제거\n",
    "#     cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),  # 교차 검증을 위한 전략. StratifiedKFold 사용\n",
    "#     verbose=1  # 실행 과정에서 출력할 메시지의 양. 높을수록 더 많은 메시지 출력\n",
    "# )\n",
    "\n",
    "# # 피처 선택을 위한 RFECV 적용\n",
    "# rfe_selector.fit(X_train_select, y_train_select)\n",
    "\n",
    "# # 선택된 피처의 불리언 마스크를 가져옴\n",
    "# rfe_support = rfe_selector.get_support()\n",
    "\n",
    "# # 선택된 피처의 이름을 가져옴\n",
    "# rfe_feature = X_train_select.loc[:, rfe_support].columns.tolist()\n",
    "\n",
    "# print(f'불량단계 예측 사용 변수 목록: {rfe_feature}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee06b47-bdf2-47b0-8e60-b5777882513b",
   "metadata": {},
   "source": [
    "#### Sequential Feature Selection (SFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6db32042-acdd-4f32-b463-0d9b3cd5e2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# # SFS 초기화\n",
    "# sfs = SFS(estimator=XGBClassifier(eval_metric='error'), \n",
    "#            k_features=12,  # 선택할 특성의 수\n",
    "#            forward=True,   # True로 설정하면 SFS, False로 설정하면 SBS\n",
    "#            floating=False, # False로 설정하면 일반 SFS/SBS, True로 설정하면 SFFS/SBFS\n",
    "#            verbose=2,\n",
    "#            scoring='accuracy', # 성능 평가 지표\n",
    "#            cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42))  # 5-겹 교차 검증 사용\n",
    "\n",
    "# # SFS 적용\n",
    "# sfs = sfs.fit(X_train_select, y_train_select)\n",
    "\n",
    "# # 선택된 변수 목록\n",
    "# sfs_feature = list(sfs.k_feature_idx_)\n",
    "# print(f'불량단계 예측 사용 변수 목록 (인덱스): {sfs_feature}')\n",
    "\n",
    "# # 선택된 변수의 이름을 가져오기\n",
    "# sfs_feature_names = [X_train_select.columns[i] for i in sfs_feature]\n",
    "# print(f'불량단계 예측 사용 변수 목록 (변수명): {sfs_feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dad3624-2d45-4654-ba0a-1975c87795a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 136 entries, 0 to 135\n",
      "Data columns (total 37 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   DZ1_OP_AVG     136 non-null    float64\n",
      " 1   DZ1_OP_Std     136 non-null    float64\n",
      " 2   DZ2_OP_AVG     136 non-null    float64\n",
      " 3   DZ2_OP_Std     136 non-null    float64\n",
      " 4   DZ1_TEMP_AVG   136 non-null    float64\n",
      " 5   DZ1_TEMP_Std   136 non-null    float64\n",
      " 6   DZ2_TEMP_AVG   136 non-null    float64\n",
      " 7   DZ2_TEMP_Std   136 non-null    float64\n",
      " 8   CLEAN_AVG      136 non-null    float64\n",
      " 9   CLEAN_Std      136 non-null    float64\n",
      " 10  HDZ1_OP_AVG    136 non-null    float64\n",
      " 11  HDZ1_OP_Std    136 non-null    float64\n",
      " 12  HDZ2_OP_AVG    136 non-null    float64\n",
      " 13  HDZ2_OP_Std    136 non-null    float64\n",
      " 14  HDZ3_OP_AVG    136 non-null    float64\n",
      " 15  HDZ3_OP_Std    136 non-null    float64\n",
      " 16  HDZ4_OP_AVG    136 non-null    float64\n",
      " 17  HDZ4_OP_Std    136 non-null    float64\n",
      " 18  HDZ_CP_AVG     136 non-null    float64\n",
      " 19  HDZ_CP_Std     136 non-null    float64\n",
      " 20  HDZ1_TEMP_AVG  136 non-null    float64\n",
      " 21  HDZ1_TEMP_Std  136 non-null    float64\n",
      " 22  HDZ2_TEMP_AVG  136 non-null    float64\n",
      " 23  HDZ2_TEMP_Std  136 non-null    float64\n",
      " 24  HDZ3_TEMP_AVG  136 non-null    float64\n",
      " 25  HDZ3_TEMP_Std  136 non-null    float64\n",
      " 26  HDZ4_TEMP_AVG  136 non-null    float64\n",
      " 27  HDZ4_TEMP_Std  136 non-null    float64\n",
      " 28  SCZ1_TEMP_AVG  136 non-null    float64\n",
      " 29  SCZ1_TEMP_Std  136 non-null    float64\n",
      " 30  SCZ2_TEMP_AVG  136 non-null    float64\n",
      " 31  SCZ2_TEMP_Std  136 non-null    float64\n",
      " 32  STZ1_TEMP_AVG  136 non-null    float64\n",
      " 33  STZ1_TEMP_Std  136 non-null    float64\n",
      " 34  STZ2_TEMP_AVG  136 non-null    float64\n",
      " 35  STZ2_TEMP_Std  136 non-null    float64\n",
      " 36  DS             136 non-null    object \n",
      "dtypes: float64(36), object(1)\n",
      "memory usage: 39.4+ KB\n"
     ]
    }
   ],
   "source": [
    "Standard_Total.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2ccdb85e-4672-484d-aadc-fe61d5a94020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_X = Standard_Total[['DZ1_OP_AVG', 'DZ1_TEMP_Std', 'DZ2_TEMP_AVG'\n",
    "#                           , 'HDZ1_OP_Std', 'HDZ_CP_AVG', 'HDZ3_TEMP_AVG'\n",
    "#                           , 'HDZ4_TEMP_Std', 'SCZ1_TEMP_Std', 'SCZ2_TEMP_AVG'\n",
    "#                           , 'SCZ2_TEMP_Std', 'STZ1_TEMP_AVG', 'STZ1_TEMP_Std']]\n",
    "\n",
    "final_X = Standard_Total[rfe_feature]\n",
    "\n",
    "# 가이드북\n",
    "# final_X = Standard_Total[['DZ1_OP_Std', 'DZ1_TEMP_Std', 'HDZ1_OP_AVG', 'HDZ1_OP_Std', \n",
    "# 'HDZ2_OP_AVG', 'HDZ_CP_AVG', 'HDZ1_TEMP_AVG', 'HDZ4_TEMP_Std', 'SCZ1_TEMP_Std', \n",
    "# 'SCZ2_TEMP_AVG', 'SCZ2_TEMP_Std', 'STZ1_TEMP_AVG']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27d0c81b-e294-4d23-a26b-82e4c7fc0e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     DZ1_TEMP_Std  DZ2_TEMP_AVG  HDZ1_OP_AVG  HDZ1_OP_Std  HDZ3_OP_AVG  \\\n",
      "0          0.5939      100.0619      75.7122      22.9797      50.6809   \n",
      "1          0.5154      100.0650      74.8979      23.4053      52.0143   \n",
      "2          0.4727      100.0216      70.7003      23.6703      48.2632   \n",
      "3          0.3314      100.0097      77.3254      15.4611      50.5714   \n",
      "4          0.6553      100.0437      74.7738      23.5540      50.2557   \n",
      "..            ...           ...          ...          ...          ...   \n",
      "131        0.3814      100.0795      73.5945      22.9711      54.7538   \n",
      "132        0.3145      100.0053      70.1365      20.6672      54.4757   \n",
      "133        0.3480      100.0262      73.6517      23.2575      54.3678   \n",
      "134        0.3819      100.0024      73.9339      22.2451      55.0990   \n",
      "135        0.4184      100.2491      74.5356      21.7632      54.7845   \n",
      "\n",
      "     HDZ4_OP_Std  HDZ1_TEMP_AVG  HDZ4_TEMP_Std  SCZ1_TEMP_AVG  SCZ2_TEMP_AVG  \\\n",
      "0         2.5042       859.4869         0.5534       282.5815       280.1490   \n",
      "1         2.2398       859.3333         0.4805       282.7882       279.7723   \n",
      "2         2.1310       859.6424         0.4184       283.3309       279.3090   \n",
      "3         1.7862       859.8549         0.2967       282.8823       279.2411   \n",
      "4         2.7004       859.8177         0.5712       283.5816       277.5448   \n",
      "..           ...            ...            ...            ...            ...   \n",
      "131       1.7004       859.4466         0.3282       284.6295       280.4194   \n",
      "132       1.3197       859.8494         0.2064       284.2365       279.9876   \n",
      "133       1.6110       859.4943         0.3131       284.1908       279.9778   \n",
      "134       1.9368       859.4064         0.3430       284.7815       280.5112   \n",
      "135       1.9077       859.7048         0.3398       284.4231       280.5544   \n",
      "\n",
      "     SCZ2_TEMP_Std  STZ1_TEMP_Std  \n",
      "0           6.0339         0.1270  \n",
      "1           7.1615         0.1012  \n",
      "2           6.6652         0.1212  \n",
      "3           6.5374         0.1000  \n",
      "4           5.3659         0.0967  \n",
      "..             ...            ...  \n",
      "131         6.6961         0.1106  \n",
      "132         6.6123         0.1730  \n",
      "133         6.5379         0.0963  \n",
      "134         6.7837         0.1585  \n",
      "135         6.4382         0.1357  \n",
      "\n",
      "[136 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(final_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "332bd561-0972-4965-ae15-d45f6909db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(final_X, y, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30636cde-6dfa-4b3f-8958-c271b94fa9e8",
   "metadata": {},
   "source": [
    "#### 04-03. StandardScaler_Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ab6589f3-0c08-4588-8f9b-7d1edf8f2758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 변형 객체 생성\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # 학습 데이터 스케일링\n",
    "# X_train_scaled = S_scaler.fit_transform(X_train)\n",
    "\n",
    "# # 테스트 데이터 스케일링\n",
    "# X_test_scaled = S_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52f474-077e-4dbe-9e3f-b511937d52a2",
   "metadata": {},
   "source": [
    "#### 04-04. RobustScaler_Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9525eef2-d30f-4145-b96d-5093647a6fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변형 객체 생성\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# 학습 데이터 스케일링\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 테스트 데이터 스케일링\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f39c7b6f-dc3e-4717-8f81-f8f252e88049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 280 candidates, totalling 1400 fits\n",
      "XGBoost best 파라미터: {'learning_rate': 0.001, 'max_depth': 2, 'n_estimators': 20}\n",
      "불량탐지 XGBoost f1_score : 0.41666666666666663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# K-Fold 교차검증 설정\n",
    "# n_splits: 데이터를 5개의 폴드로 나눔\n",
    "# shuffle: 데이터를 섞은 후 분할\n",
    "# random_state: 재현성을 위한 랜덤 시드\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "parameters_xc = {\n",
    "    # n_estimators: 부스팅 라운드 수\n",
    "    \"n_estimators\": [20, 50, 100, 150, 200, 250, 300],\n",
    "    # learning_rate: 학습률 (부스팅 스텝별 가중치 축소)\n",
    "    \"learning_rate\": [0.001, 0.05, 0.1, 0.15, 0.2],\n",
    "    # max_depth: 트리의 최대 깊이\n",
    "    \"max_depth\": [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "}\n",
    "\n",
    "# GridSearchCV를 사용하여 모델 생성\n",
    "# XGBClassifier: XGBoost 분류 모델\n",
    "# eval_metric: 모델의 평가 기준 (오류율)\n",
    "# cv: 교차 검증 설정\n",
    "# verbose: 로깅 레벨 (1: 에포크마다 출력)\n",
    "# n_jobs: 병렬로 실행할 작업 수 (-1: 모든 사용 가능한 프로세서 사용)\n",
    "model_xc = GridSearchCV(XGBClassifier(eval_metric='error'), parameters_xc, cv=kfold, verbose=1, n_jobs=-1)\n",
    "\n",
    "# 모델 학습\n",
    "model_xc.fit(X_train, y_train)\n",
    "print(f\"XGBoost best 파라미터: {model_xc.best_params_}\")\n",
    "\n",
    "# 최적의 하이퍼파라미터를 사용하는 XGBoost 모델\n",
    "best_model_xc = model_xc.best_estimator_\n",
    "best_model_xc.fit(X_train, y_train)\n",
    "\n",
    "# 모델로부터 예측값 얻기\n",
    "y_pred_xc = best_model_xc.predict(X_test)\n",
    "# F1 스코어 계산 (macro: 클래스별 F1 평균)\n",
    "score_xc = f1_score(y_test, y_pred_xc, average='macro')\n",
    "print(f\"불량탐지 XGBoost f1_score :\", score_xc)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a5eff0f-719d-4e29-8b86-273fb1194f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_xc)\n",
    "class_names = ['안정', '위험']\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "ax = sns.heatmap(cm, annot=True, cmap='Blues', linewidths=1, fmt=\"d\",\n",
    "                 xticklabels=['안정', '위험'], yticklabels=['안정', '위험'])\n",
    "ax.set(title='Confusion Matrix', \n",
    "        ylabel='True label', \n",
    "        xlabel='Predicted label')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dcdaebb9-5ab3-4701-a2ac-756f646a2525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          안정       0.71      1.00      0.83        20\n",
      "          위험       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.36      0.50      0.42        28\n",
      "weighted avg       0.51      0.71      0.60        28\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Documents\\League\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\Documents\\League\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\admin\\Documents\\League\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_xc = best_model_xc.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_xc, target_names=['안정', '위험']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab11ae92-fe76-43a3-bc2b-57ba5a3b8604",
   "metadata": {},
   "source": [
    "### 05. 알고리즘 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d35117d-0ff1-42c9-9ac5-b3df7ed6126d",
   "metadata": {},
   "source": [
    "#### 05-01. 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d19f3fd1-4725-4e7a-bbc5-861cd73ee081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "Random Forest best 파라미터: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "불량탐지 Random Forest f1_score : 0.5130434782608696\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# K-Fold 교차검증\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "parameters_rf = {\n",
    "    \"n_estimators\": [10, 50, 100, 150, 200],\n",
    "    \"max_depth\": [None, 10, 20, 30, 40, 50],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4]\n",
    "}\n",
    "\n",
    "# 모델 생성\n",
    "model_rf = GridSearchCV(RandomForestClassifier(random_state=1), parameters_rf, cv=kfold, verbose=1, n_jobs=-1)\n",
    "\n",
    "# 모델 학습\n",
    "model_rf.fit(X_train, y_train)\n",
    "print(f\"Random Forest best 파라미터: {model_rf.best_params_}\")\n",
    "\n",
    "# Random Forest 모델\n",
    "best_model_rf = model_rf.best_estimator_\n",
    "best_model_rf.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "score_rf = f1_score(y_test, y_pred_rf, average='macro')\n",
    "print(f\"불량탐지 Random Forest f1_score :\", score_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a914bb71-b764-4ddd-b1bb-974234b0c8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          안정       0.73      0.95      0.83        20\n",
      "          위험       0.50      0.12      0.20         8\n",
      "\n",
      "    accuracy                           0.71        28\n",
      "   macro avg       0.62      0.54      0.51        28\n",
      "weighted avg       0.66      0.71      0.65        28\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 포레스트 모델을 사용하여 예측 수행\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "\n",
    "# 분류 보고서 출력\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['안정', '위험']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ad870-0946-48d0-9c65-39f6107e233a",
   "metadata": {},
   "source": [
    "#### 05-02 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c642d7b1-67a9-4880-8cb5-09ba6ce3a713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Logistic Regression best 파라미터: {'C': 0.001, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "불량탐지 Logistic Regression f1_score : 0.41666666666666663\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# K-Fold 교차검증\n",
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "# 하이퍼파라미터\n",
    "parameters_lr = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"penalty\": [\"l2\", \"none\"],\n",
    "    \"solver\": [\"lbfgs\", \"newton-cg\", \"sag\", \"saga\"]\n",
    "}\n",
    "\n",
    "# 모델 생성\n",
    "model_lr = GridSearchCV(LogisticRegression(random_state=1, max_iter=1000), parameters_lr, cv=kfold, verbose=1, n_jobs=-1, error_score='raise')\n",
    "\n",
    "# 모델 학습\n",
    "model_lr.fit(X_train, y_train)\n",
    "print(f\"Logistic Regression best 파라미터: {model_lr.best_params_}\")\n",
    "\n",
    "# 로지스틱 회귀 모델\n",
    "best_model_lr = model_lr.best_estimator_\n",
    "best_model_lr.fit(X_train, y_train)\n",
    "\n",
    "# 모델 예측\n",
    "y_pred_lr = best_model_lr.predict(X_test)\n",
    "score_lr = f1_score(y_test, y_pred_lr, average='macro')\n",
    "print(f\"불량탐지 Logistic Regression f1_score :\", score_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b2f8f2-83a6-4e38-a26d-5c2e6bbda669",
   "metadata": {},
   "source": [
    "#### 05-03. 인공신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "215d40e0-9028-4790-ba48-d803a292c19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "80/80 [==============================] - 1s 3ms/step - loss: 0.7237 - accuracy: 0.5063 - val_loss: 0.7234 - val_accuracy: 0.4938\n",
      "Epoch 2/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.5125 - val_loss: 0.7154 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.5203 - val_loss: 0.7105 - val_accuracy: 0.5312\n",
      "Epoch 4/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6968 - accuracy: 0.5109 - val_loss: 0.7076 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6926 - accuracy: 0.5203 - val_loss: 0.7064 - val_accuracy: 0.4875\n",
      "Epoch 6/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.5219 - val_loss: 0.7048 - val_accuracy: 0.5188\n",
      "Epoch 7/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6852 - accuracy: 0.5391 - val_loss: 0.7040 - val_accuracy: 0.5250\n",
      "Epoch 8/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6822 - accuracy: 0.5578 - val_loss: 0.7035 - val_accuracy: 0.5312\n",
      "Epoch 9/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6793 - accuracy: 0.5703 - val_loss: 0.7030 - val_accuracy: 0.5312\n",
      "Epoch 10/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.5766 - val_loss: 0.7024 - val_accuracy: 0.5312\n",
      "Epoch 11/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6739 - accuracy: 0.5922 - val_loss: 0.7021 - val_accuracy: 0.5312\n",
      "Epoch 12/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6711 - accuracy: 0.5953 - val_loss: 0.7019 - val_accuracy: 0.5188\n",
      "Epoch 13/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6687 - accuracy: 0.6016 - val_loss: 0.7015 - val_accuracy: 0.5188\n",
      "Epoch 14/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6662 - accuracy: 0.6187 - val_loss: 0.7015 - val_accuracy: 0.5125\n",
      "Epoch 15/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6638 - accuracy: 0.6141 - val_loss: 0.7012 - val_accuracy: 0.5125\n",
      "Epoch 16/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.6234 - val_loss: 0.7011 - val_accuracy: 0.5188\n",
      "Epoch 17/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6592 - accuracy: 0.6328 - val_loss: 0.7012 - val_accuracy: 0.5188\n",
      "Epoch 18/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6571 - accuracy: 0.6391 - val_loss: 0.7009 - val_accuracy: 0.5188\n",
      "Epoch 19/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6545 - accuracy: 0.6406 - val_loss: 0.7010 - val_accuracy: 0.5188\n",
      "Epoch 20/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.6438 - val_loss: 0.7011 - val_accuracy: 0.5250\n",
      "Epoch 21/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.6516 - val_loss: 0.7011 - val_accuracy: 0.5250\n",
      "Epoch 22/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6478 - accuracy: 0.6625 - val_loss: 0.7013 - val_accuracy: 0.5312\n",
      "Epoch 23/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.6641 - val_loss: 0.7014 - val_accuracy: 0.5250\n",
      "Epoch 24/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.6609 - val_loss: 0.7015 - val_accuracy: 0.5312\n",
      "Epoch 25/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6409 - accuracy: 0.6609 - val_loss: 0.7018 - val_accuracy: 0.5375\n",
      "Epoch 26/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6387 - accuracy: 0.6766 - val_loss: 0.7021 - val_accuracy: 0.5500\n",
      "Epoch 27/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6365 - accuracy: 0.6812 - val_loss: 0.7025 - val_accuracy: 0.5500\n",
      "Epoch 28/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6342 - accuracy: 0.6844 - val_loss: 0.7027 - val_accuracy: 0.5437\n",
      "Epoch 29/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6322 - accuracy: 0.6812 - val_loss: 0.7032 - val_accuracy: 0.5500\n",
      "Epoch 30/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6301 - accuracy: 0.6891 - val_loss: 0.7037 - val_accuracy: 0.5562\n",
      "Epoch 31/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6280 - accuracy: 0.6969 - val_loss: 0.7038 - val_accuracy: 0.5375\n",
      "Epoch 32/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.6969 - val_loss: 0.7040 - val_accuracy: 0.5312\n",
      "Epoch 33/100\n",
      "80/80 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.7000 - val_loss: 0.7046 - val_accuracy: 0.5250\n",
      "7/7 [==============================] - 0s 665us/step\n",
      "불량탐지 인공 신경망 f1_score: 0.4608890245142915\n"
     ]
    }
   ],
   "source": [
    "# 인공신경망: 여러 층의 뉴런으로 구성된 모델로, 복잡한 비선형 문제를 해결할 수 있습니다.\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 샘플 데이터 생성\n",
    "np.random.seed(1)\n",
    "X_train = np.random.randn(800, 20)  # 800개의 샘플과 20개의 특성을 가진 훈련 데이터\n",
    "y_train = np.random.randint(2, size=800)  # 0 또는 1의 값을 가진 훈련 레이블, 불균형한 데이터 분포를 체크할 필요가 있음\n",
    "X_test = np.random.randn(200, 20)  # 200개의 샘플과 20개의 특성을 가진 테스트 데이터\n",
    "y_test = np.random.randint(2, size=200)  # 0 또는 1의 값을 가진 테스트 레이블\n",
    "\n",
    "# 모델 구축\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(20,)),  # 64개의 유닛을 가진 Dense 층, 활성화 함수는 ReLU\n",
    "    layers.Dense(32, activation='relu'),  # 32개의 유닛을 가진 Dense 층, 활성화 함수는 ReLU\n",
    "    layers.Dense(1, activation='sigmoid')  # 1개의 유닛을 가진 Dense 층, 활성화 함수는 시그모이드, 이진 분류 문제에 적합\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Adam 옵티마이저 사용, 학습률은 0.001\n",
    "# 손실 함수로 이진 교차 엔트로피 사용, 평가 지표로 정확도 사용\n",
    "\n",
    "# EarlyStopping 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',        # 검증 손실을 모니터링\n",
    "    patience=15,                # N개 에포크 동안 성능 향상이 없으면 훈련을 중단\n",
    "    restore_best_weights=True  # 훈련 중단 시 가장 좋은 모델의 가중치를 복원\n",
    ")\n",
    "\n",
    "# 모델 훈련\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,  # 최대 100 에포크 동안 훈련\n",
    "    batch_size=8,  # 각 배치의 샘플 수는 8\n",
    "    validation_split=0.2,  # 20%의 데이터를 검증 데이터로 사용\n",
    "    callbacks=[early_stopping]  # EarlyStopping 콜백 사용\n",
    ")\n",
    "\n",
    "# 모델 예측\n",
    "y_pred = model.predict(X_test) > 0.5  # 예측된 확률이 0.5보다 큰 경우 1로, 그렇지 않은 경우 0으로 분류\n",
    "y_pred = y_pred.astype(int)\n",
    "\n",
    "# F1 스코어 계산\n",
    "score = f1_score(y_test, y_pred, average='macro')  # F1 스코어 계산, 클래스 불균형을 고려해 macro 평균 사용\n",
    "print(f\"불량탐지 인공 신경망 f1_score: {score}\")\n",
    "\n",
    "# 개선할 수 있는 부분:\n",
    "# 1. 데이터 분포 확인: y_train과 y_test의 레이블 분포가 고르지 않다면, 모델 학습에 영향을 줄 수 있습니다.\n",
    "# 2. 데이터 전처리: 입력 데이터의 스케일이 크게 다르다면, 특성 스케일링을 고려할 수 있습니다.\n",
    "# 3. 모델 구조 및 하이퍼파라미터 튜닝: 모델의 성능을 높이기 위해 모델 구조나 하이퍼파라미터를 튜닝할 수 있습니다.\n",
    "# 4. 성능 지표 선택: 클래스 불균형이 심각하다면, 정확도 대신 다른 성능 지표를 고려할 수 있습니다.\n",
    "# 5. 더 복잡한 모델 고려: 문제의 복잡도에 따라 더 복잡한 모델을 고려할 수 있습니다.\n",
    "# 6. 데이터 양 증가: 더 많은 데이터를 사용하면 모델의 성능이 향상될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e76ddeaf-1435-422e-9b08-2b2d3570344a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 831us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          안정       0.44      0.35      0.39        97\n",
      "          위험       0.49      0.58      0.53       103\n",
      "\n",
      "    accuracy                           0.47       200\n",
      "   macro avg       0.46      0.47      0.46       200\n",
      "weighted avg       0.47      0.47      0.46       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델을 사용하여 예측 수행\n",
    "y_pred_nn = model.predict(X_test) > 0.5\n",
    "y_pred_nn = y_pred_nn.astype(int)\n",
    "\n",
    "# 분류 보고서 출력\n",
    "print(classification_report(y_test, y_pred_nn, target_names=['안정', '위험']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205a0086-5ee5-40b9-bc08-a25aa1153dc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
