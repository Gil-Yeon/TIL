{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 데이터 내려받기 테스트"],"metadata":{"id":"_RX4BSe08ali"}},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":95},"id":"p9yw4ICJzQOi","executionInfo":{"status":"ok","timestamp":1693492214418,"user_tz":-540,"elapsed":88184,"user":{"displayName":"구국이","userId":"07893391965781894103"}},"outputId":"727a2e20-f343-4dcd-9299-792b8bcbc9d2"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-a9ba135c-dbaf-4c87-aedb-2a33b9ee5dee\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-a9ba135c-dbaf-4c87-aedb-2a33b9ee5dee\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"spa8453\",\"key\":\"fdddd62cb348e218791779c783209cd0\"}'}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"ytPmvx1dxZ5J","executionInfo":{"status":"ok","timestamp":1693492214419,"user_tz":-540,"elapsed":5,"user":{"displayName":"구국이","userId":"07893391965781894103"}}},"outputs":[],"source":["!mkdir ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"code","source":["!kaggle competitions download -c titanic"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkvK2jO_xlIu","executionInfo":{"status":"ok","timestamp":1693492216419,"user_tz":-540,"elapsed":2003,"user":{"displayName":"구국이","userId":"07893391965781894103"}},"outputId":"31b34631-2e70-4269-f5f1-c4b76e038c8b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading titanic.zip to /content\n","\r  0% 0.00/34.1k [00:00<?, ?B/s]\n","\r100% 34.1k/34.1k [00:00<00:00, 1.16MB/s]\n"]}]},{"cell_type":"code","source":["!unzip titanic.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NKGKK_Prxq-Z","executionInfo":{"status":"ok","timestamp":1693492216420,"user_tz":-540,"elapsed":9,"user":{"displayName":"구국이","userId":"07893391965781894103"}},"outputId":"8ea4f813-2278-4513-eadf-a5790f31e403"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  titanic.zip\n","  inflating: gender_submission.csv   \n","  inflating: test.csv                \n","  inflating: train.csv               \n"]}]},{"cell_type":"markdown","source":["# 간단한 합성곱 만들기\n","- 합성곱 층과 MaxPooling 층을 연달아서 쌓아 올림"],"metadata":{"id":"WaYPsALtxulJ"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","inputs = keras.Input(shape=(28, 28, 1)) # 입력층 만듬\n","\n","# 합성곱 층, filters=32 깊이\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs) # 함수형 API\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x) #\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","\n","# 출력층\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(10, activation=\"softmax\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"tHd93wMAx0RI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 요약"],"metadata":{"id":"RXgpEQHtzG9a"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"9JsUNcNny4L6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MNIST 이미지 합성곱 훈련\n","- 2장의 연결 네트워크는 97.8%"],"metadata":{"id":"rI3Fql3P4ill"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","train_images = train_images.reshape((60000, 28, 28, 1))\n","train_images = train_images.astype(\"float32\") / 255\n","test_images = test_images.reshape((10000, 28, 28, 1))\n","test_images = test_images.astype(\"float32\") / 255\n","model.compile(optimizer=\"rmsprop\",\n","    loss=\"sparse_categorical_crossentropy\",\n","    metrics=[\"accuracy\"])\n","model.fit(train_images, train_labels, epochs=5, batch_size=64)"],"metadata":{"id":"NZArmJLT4o0c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print('테스트 정확도 : ', test_acc)"],"metadata":{"id":"3GF5SkzJ5w8m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 최대 풀링 연산\n","- p292\n","- 최대 풀링 층이 빠진 잘못된 구조의 합성곱\n","  - 가장 큰 문제점 : 이미지 압축이 안됨\n","- CNN 구조 파악에 도움 : http://alexlenail.me/NN-SVG/index.html"],"metadata":{"id":"ZLKDsVSk66AF"}},{"cell_type":"code","source":["inputs = keras.Input(shape=(28, 28, 1))\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(10, activation=\"softmax\")(x)\n","model_no_max_pool = keras.Model(inputs=inputs, outputs=outputs)\n","model_no_max_pool.summary()"],"metadata":{"id":"xE0MR_6Y7EEL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 개와 고양이로 이루어진 소규모 데이터셋에서 밑바닥부터 컨브넷 훈련"],"metadata":{"id":"L2mwF7Kg8Vbe"}},{"cell_type":"code","source":["!kaggle competitions download -c dogs-vs-cats"],"metadata":{"id":"_Wrpy2418f1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!unzip -qq dogs-vs-cats.zip\n","!unzip -qq train.zip"],"metadata":{"id":"9n2mWI129t0r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os, shutil, pathlib\n","\n","original_dir = pathlib.Path(\"train\")\n","new_base_dir = pathlib.Path(\"cats_vs_dogs_small\")\n","\n","def make_subset(subset_name, start_index, end_index):\n","    for category in (\"cat\", \"dog\"):\n","        dir = new_base_dir / subset_name / category\n","        os.makedirs(dir)\n","        fnames = [f\"{category}.{i}.jpg\" for i in range(start_index, end_index)]\n","        for fname in fnames:\n","            shutil.copyfile(src=original_dir / fname,\n","                            dst=dir / fname)\n","\n","make_subset(\"train\", start_index=0, end_index=1000)\n","make_subset(\"validation\", start_index=1000, end_index=1500)\n","make_subset(\"test\", start_index=1500, end_index=2500)"],"metadata":{"id":"TcylvNyC-K_e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 만들기"],"metadata":{"id":"aDjBkJBa_6g1"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","inputs = keras.Input(shape=(180, 180, 3)) # 180 * 180 크기의 RGB 이미지를 기대한다.\n","x = layers.Rescaling(1./255)(inputs) # 입력을 255로 나누어 [0, 1]범위로 스케일을 조정한다.\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)"],"metadata":{"id":"xqDKx3Z2_M0k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"f7ON50InBd6u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='binary_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])"],"metadata":{"id":"wfg1p8i9B4cP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 데이터 전처리\n","- p301"],"metadata":{"id":"96-BRCk3UkR_"}},{"cell_type":"code","source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","new_base_dir = pathlib.Path('cats_vs_dogs_small')\n","\n","train_dataset = image_dataset_from_directory(\n","    new_base_dir / 'train',\n","    image_size=(180, 180),\n","    batch_size = 32\n",")\n","\n","validation_dataset = image_dataset_from_directory(\n","    new_base_dir / 'validation',\n","    image_size=(180, 180),\n","    batch_size = 32\n",")\n","\n","test_dataset = image_dataset_from_directory(\n","    new_base_dir / 'test',\n","    image_size=(180, 180),\n","    batch_size = 32\n",")"],"metadata":{"id":"lvOXisDTUEB_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 텐서플로 Dataset 객체 이해하기\n","- 샘플 데이터 1000개 만들기"],"metadata":{"id":"9gaSEsxoVhDN"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","random_numbers = np.random.normal(size=(1000, 16))\n","dataset = tf.data.Dataset.from_tensor_slices(random_numbers)"],"metadata":{"id":"azFgJ0wPXHMy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 하나의 샘플 확인하기"],"metadata":{"id":"THppUTA0XI1e"}},{"cell_type":"code","source":["for i, element in enumerate(dataset):\n","    print(element.shape)\n","    if i >= 2:\n","        break"],"metadata":{"id":"nh5Vz28bXKRo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 데이터 배치"],"metadata":{"id":"zZerpTlHXQ0F"}},{"cell_type":"code","source":["batched_dataset = dataset.batch(32)\n","for i, element in enumerate(batched_dataset):\n","    print(element.shape)\n","    if i >= 2:\n","        break"],"metadata":{"id":"CQ1P0A6vXSM6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 원소 크기를 (16, ) --> (4, 4)"],"metadata":{"id":"AQkbyp4KXjeO"}},{"cell_type":"code","source":["reshaped_dataset = dataset.map(lambda x: tf.reshape(x, (2, 8)))\n","for i, element in enumerate(reshaped_dataset):\n","    print(element.shape)\n","    if i >= 2:\n","        break"],"metadata":{"id":"SuPq7zr7XozR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Dataset이 반환하는 데이터 및 레이블 크기 확인"],"metadata":{"id":"ILGlM9gjX5Fq"}},{"cell_type":"code","source":["for data_batch, labels_batch in train_dataset:\n","  print('데이터 배치 크기:', data_batch.shape)\n","  print('레이블 배치 크기:', labels_batch.shape)\n","  break"],"metadata":{"id":"6kg-AVC_X9Yh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 훈련하기"],"metadata":{"id":"xt9y8VsfYlK6"}},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath = 'convnet_from_scratch.keras',\n","        save_best_only=True, # 1epoch vs 2 epoch\n","        monitor='val_loss'\n","    )\n","]\n","\n","history = model.fit(\n","    train_dataset,\n","    epochs = 30,\n","    validation_data = validation_dataset,\n","    callbacks = callbacks\n",")"],"metadata":{"id":"wb0yg3PxYmtS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","def vis(history):\n","  history_dict = history.history\n","  loss_values = history_dict[\"loss\"]\n","  val_loss_values = history_dict[\"val_loss\"]\n","  acc = history_dict[\"accuracy\"]\n","  val_acc = history_dict[\"val_accuracy\"]\n","  epochs = range(1, len(loss_values) + 1)\n","\n","  figure, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 8))\n","\n","  ax[0].plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n","  ax[0].plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n","  ax[0].set_title(\"Training and validation loss\")\n","  ax[0].set_xlabel(\"Epochs\")\n","  ax[0].set_ylabel(\"Loss\")\n","  ax[0].legend()\n","\n","  ax[1].plot(epochs, acc, \"bo\", label=\"Training acc\")\n","  ax[1].plot(epochs, val_acc, \"b\", label=\"Validation acc\")\n","  ax[1].set_title(\"Training and validation accuracy\")\n","  ax[1].set_xlabel(\"Epochs\")\n","  ax[1].set_ylabel(\"Accuracy\")\n","  ax[1].legend()\n","\n","  plt.show()"],"metadata":{"id":"rC1OreVZaE0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vis(history)"],"metadata":{"id":"Qtgt62PFamIg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 테스트 모델에서 모델 평가"],"metadata":{"id":"Nue9B5S0bgc3"}},{"cell_type":"code","source":["test_model = keras.models.load_model(\"convnet_from_scratch.keras\")\n","test_loss, test_acc = test_model.evaluate(test_dataset)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"],"metadata":{"id":"84EperTZbdSI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 데이터 증식 사용"],"metadata":{"id":"jlw7N43YhYlK"}},{"cell_type":"code","source":["data_augmentation = keras.Sequential([\n","    layers.RandomFlip('horizontal'),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.2)\n","])"],"metadata":{"id":"PKaBGUdJdOTJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 10))\n","for images, _ in train_dataset.take(1):\n","    for i in range(9):\n","        augmented_images = data_augmentation(images)\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n","        plt.axis(\"off\")"],"metadata":{"id":"unLtLKsQhvNG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inputs = keras.Input(shape=(180, 180, 3)) # 입력층\n","x = data_augmentation(inputs) # 데이터 증식 단계 통과\n","x = layers.Rescaling(1./255)(x) # 이미지 [0, 1]\n","\n","# 은닉층\n","x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D(pool_size=2)(x)\n","x = layers.Conv2D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","x = layers.Flatten()(x)\n","\n","x = layers.Dropout(0.5)(x) # 드롭아웃을 적용하면 과대적합이 덜 일어난다.\n","\n","# 출력층\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs=inputs, outputs=outputs)\n","\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"laKieDJbiHQK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"fg0s_15TjJSU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 모델 훈련하기"],"metadata":{"id":"vfmkrPoAmlVu"}},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"convnet_from_scratch_with_augmentation.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","\n","history = model.fit(\n","    train_dataset,\n","    epochs=100,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"],"metadata":{"id":"GpO6fXs3om6P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 그래프 확인"],"metadata":{"id":"Ott4SnpbmgtC"}},{"cell_type":"code","source":["vis(history)"],"metadata":{"id":"OMIW3rqmoqqI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 테스트 세트에서 모델 정확도 확인"],"metadata":{"id":"c4PmamkQl9jP"}},{"cell_type":"code","source":["test_model = keras.models.load_model(\"convnet_from_scratch_with_augmentation.keras\")\n","test_loss, test_acc = test_model.evaluate(test_dataset)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"],"metadata":{"id":"QvS2WaP_pMQ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 머신러닝 프로젝트 vs 딥러닝 프로젝트\n","- 머신러닝 프로젝트의 핵심은 정확도 + 변수 추출 과정 설명 중요\n","  - 분석가 지망생들이 많이 함\n","- 딥러닝 프로젝트의 핵심은 정확도 + 어떤 모델 썼느냐 + 모델에 대한 설명(영어 논문 또는 한글로 번역한 유튜브 공부)\n","  - 컴공 출신들이 많이 함"],"metadata":{"id":"-VbGxxPLoDLT"}},{"cell_type":"markdown","source":["# 사전 훈련된 모델 활용\n","- pretrained model"],"metadata":{"id":"6wOVtrUQpOFt"}},{"cell_type":"markdown","source":["## 사전 훈련된 모델\n","- 일반 정확도 : 72.3\n","- 데이터 증식 정확도 : 82.8\n","- 사전 훈련된 모델 : 97.5\n","- 모델 미세 조정하기 : 98.5\n","- 결론 : 딥러닝 프로젝트 진행 시,\n","  - 주요 키워드 --> 사전 훈련된 모델 & 모델 미세 조정하기 --> chat gpt에 사전 훈련된 모델 샘플 코드 받아서 쓰기"],"metadata":{"id":"BPrymAxanKV3"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","import matplotlib.pyplot as plt"],"metadata":{"id":"7Y-z7BlnrArK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- p312\n","- 훈련된 합성곱 기반 층 (동결)\n","  - vgg16에서 정의된 구조를 그대로 이어받아서 사용하겠다.\n","- ImageNet 데이터셋에서 훈련했다! ==> 대용량 & 다양한 이미지를 학습했다."],"metadata":{"id":"w3UID7--rX2N"}},{"cell_type":"code","source":["from tensorflow.python.util.traceback_utils import include_frame\n","# 2014년에 제안된 모델\n","conv_base = keras.applications.vgg16.VGG16(\n","    weights='imagenet',\n","    include_top = False,\n","    input_shape = (180, 180, 3)\n",")"],"metadata":{"id":"Ky-dpPMSrXjN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"id":"wiG8Tpdjtn42"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 특성 추출\n","- 데이터 증식을 사용하지 않는 특성 추출\n"],"metadata":{"id":"3kz26wogubdb"}},{"cell_type":"code","source":["# predict() 메서드 호출 넘파이 배열로 특성을 추출\n","\n","def get_features_and_labels(dataset):\n","    all_features = [] # 특성\n","    all_labels = [] # 각 특성에 맞는 label\n","    for images, labels in dataset:\n","        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n","        features = conv_base.predict(preprocessed_images) # 고양이 1, 개 0\n","        all_features.append(features)\n","        all_labels.append(labels)\n","    return np.concatenate(all_features), np.concatenate(all_labels)"],"metadata":{"id":"uz7JTRhduzHw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 데이터 불러오기"],"metadata":{"id":"ULacnvyWvsfP"}},{"cell_type":"code","source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","train_dataset = image_dataset_from_directory(\n","    new_base_dir / \"train\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    new_base_dir / \"validation\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","test_dataset = image_dataset_from_directory(\n","    new_base_dir / \"test\",\n","    image_size=(180, 180),\n","    batch_size=32)"],"metadata":{"id":"ccki-oShwqNy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_features, train_labels =  get_features_and_labels(train_dataset)\n","val_features, val_labels =  get_features_and_labels(validation_dataset)\n","test_features, test_labels =  get_features_and_labels(test_dataset)"],"metadata":{"id":"TOATney1vuKL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_features.shape, train_labels.shape"],"metadata":{"id":"1kVFV-t4wu0e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["val_features.shape, val_labels.shape"],"metadata":{"id":"yDnByDqGwUl4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_features.shape, test_labels.shape"],"metadata":{"id":"h8qv-mIcwZfO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.applications.vgg16 import VGG16\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.applications.vgg16 import preprocess_input\n","\n","model = VGG16(weights='imagenet', include_top=False)\n","\n","img_path = keras.utils.get_file(\n","    fname=\"cat.jpg\",\n","    origin=\"https://img-datasets.s3.amazonaws.com/cat.jpg\")\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","features = model.predict(x)"],"metadata":{"id":"9R_pdYht1sRb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 출력층 정의하고 재훈련"],"metadata":{"id":"HIPb3Olr2l8l"}},{"cell_type":"code","source":["# 상단에 vgg16이 있고 그걸 참고하면 여기 출력층이 5, 5, 512\n","inputs = keras.Input(shape=(5, 5, 512))\n","x = layers.Flatten()(inputs) # Dense 특성 주입하기 전에 Flatten층을 사용합니다.\n","x = layers.Dense(256)(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","      filepath=\"feature_extraction.keras\",\n","      save_best_only=True,\n","      monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_features, train_labels,\n","    epochs=20,\n","    validation_data=(val_features, val_labels),\n","    callbacks=callbacks)"],"metadata":{"id":"aFVz3P762lYN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vis(history)"],"metadata":{"id":"L8juXUvm5Tup"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 사전 훈련된 모델 활용2"],"metadata":{"id":"BEbLKTn-8N0s"}},{"cell_type":"code","source":["from tensorflow.python.util.traceback_utils import include_frame\n","\n","conv_base = tf.keras.applications.EfficientNetV2M(\n","    weights='imagenet',\n","    include_top = False,\n","    input_shape = (180, 180, 3)\n",")"],"metadata":{"id":"dcMoCy2V8Scz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 특성 추출"],"metadata":{"id":"C8q0zOTR9SSl"}},{"cell_type":"code","source":["# predict() 메서드 호출 넘파이 배열로 특성을 추출\n","\n","def get_features_and_labels(dataset):\n","    all_features = [] # 특성\n","    all_labels = [] # 각 특성에 맞는 label\n","    for images, labels in dataset:\n","        preprocessed_images = keras.applications.vgg16.preprocess_input(images)\n","        features = conv_base.predict(preprocessed_images) # 고양이 1, 개 0\n","        all_features.append(features)\n","        all_labels.append(labels)\n","    return np.concatenate(all_features), np.concatenate(all_labels)"],"metadata":{"id":"EGGhUafo9I95"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 데이터 불러오기"],"metadata":{"id":"pzrjEUxo9Tpe"}},{"cell_type":"code","source":["from tensorflow.keras.utils import image_dataset_from_directory\n","\n","train_dataset = image_dataset_from_directory(\n","    new_base_dir / \"train\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","validation_dataset = image_dataset_from_directory(\n","    new_base_dir / \"validation\",\n","    image_size=(180, 180),\n","    batch_size=32)\n","test_dataset = image_dataset_from_directory(\n","    new_base_dir / \"test\",\n","    image_size=(180, 180),\n","    batch_size=32)"],"metadata":{"id":"eKYaQTPw9N6f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_features, train_labels =  get_features_and_labels(train_dataset)\n","val_features, val_labels =  get_features_and_labels(validation_dataset)\n","test_features, test_labels =  get_features_and_labels(test_dataset)"],"metadata":{"id":"XtjvPW0s9aIX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_features.shape, train_labels.shape\n","val_features.shape, val_labels.shape\n","test_features.shape, test_labels.shape"],"metadata":{"id":"gFYIhtdS9l3s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.applications import EfficientNetV2M\n","from tensorflow.keras.preprocessing import image\n","import numpy as np\n","\n","# Load EfficientNetV2M model\n","model = EfficientNetV2M(weights='imagenet', include_top=False)\n","\n","# Replace 'cat.jpg' and the URL with your image file information\n","img_path = tf.keras.utils.get_file(\n","    fname=\"cat.jpg\",\n","    origin=\"https://img-datasets.s3.amazonaws.com/cat.jpg\")\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)\n","x = preprocess_input(x)\n","\n","features = model.predict(x)\n"],"metadata":{"id":"hGOVSl1zB8J9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 출력층 정의하고 재훈련"],"metadata":{"id":"gXvhTvLy9Vbl"}},{"cell_type":"code","source":["# 상단에 EfficientNetV2M이 있고 그걸 참고하면 여기 출력층이 6, 6, 1280\n","inputs = keras.Input(shape=(6, 6, 1280))\n","x = layers.Flatten()(inputs) # Dense 특성 주입하기 전에 Flatten층을 사용합니다.\n","x = layers.Dense(256)(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","      filepath=\"feature_extraction.keras\",\n","      save_best_only=True,\n","      monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_features, train_labels,\n","    epochs=20,\n","    validation_data=(val_features, val_labels),\n","    callbacks=callbacks)"],"metadata":{"id":"o7A0B29M90TT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vis(history)"],"metadata":{"id":"0uIfhvwz-AET"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터 증식을 사용한 특성 추출"],"metadata":{"id":"ctAqAnwjDoMz"}},{"cell_type":"code","source":["conv_base  = keras.applications.vgg16.VGG16(\n","    weights=\"imagenet\",\n","    include_top=False)"],"metadata":{"id":"eEaSeAF-Dni8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.trainable=True\n","print(len(conv_base.trainable_weights)) # 동결 전"],"metadata":{"id":"KCf08_cVEG1-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.trainable=False\n","print(len(conv_base.trainable_weights)) # 동결 후"],"metadata":{"id":"Vkjt87UyEPGD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 데이터 증식\n","- 동결된 합성곱 기반층\n","- 밀집분류기"],"metadata":{"id":"quiryO1fEtJg"}},{"cell_type":"code","source":["data_augmentation = keras.Sequential(\n","    [\n","        layers.RandomFlip('horizontal'),\n","        layers.RandomRotation(0.1),\n","        layers.RandomZoom(0.2),\n","    ]\n",")\n","\n","# 입력층\n","inputs = keras.Input(shape=(180, 180, 3))\n","x = data_augmentation(inputs)\n","x = keras.applications.vgg16.preprocess_input(x) # 입력값의 스케일 조정\n","\n","# 은닉층 = 합성곱 층 연결 (vgg16)\n","x = conv_base(x)\n","\n","# 출력층\n","x = layers.Flatten()(x)\n","x = layers.Dense(256)(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n","model = keras.Model(inputs, outputs)\n","model.compile(loss=\"binary_crossentropy\",\n","              optimizer=\"rmsprop\",\n","              metrics=[\"accuracy\"])"],"metadata":{"id":"Zn1QvDRKEyAf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"feature_extraction_with_data_augmentation.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=20,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"],"metadata":{"id":"Dn_Dm40nF2SM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vis(history)"],"metadata":{"id":"LaR_spOVGJZj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 평가"],"metadata":{"id":"r7wBF0cbGHgm"}},{"cell_type":"code","source":["test_model = keras.models.load_model(\n","    'feature_extraction_with_data_augmentation.keras'\n",")\n","\n","test_loss, test_acc = test_model.evaluate(test_dataset)\n","print(f\"테스트 정확도: {test_acc:.3f}\")"],"metadata":{"id":"yyFSnWotGOC2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 미세 조정하기"],"metadata":{"id":"1qIHeQYMG-uZ"}},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"id":"dANQdmo9HAwF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 마지막 3개의 합성곱 층 미세조정(block4_pool까지 동결이고 block5_conv1부터 block5_pool까지는 미세조정)"],"metadata":{"id":"VWJo5mwQIJCt"}},{"cell_type":"code","source":["conv_base.trainable = True # 동결 전\n","for layer in conv_base.layers[:-4]:\n","  layer.trainable = False # 동결 처음부터~ block4_pool 동결"],"metadata":{"id":"LYyEJK-pIIud"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss=\"binary_crossentropy\",\n","              optimizer=keras.optimizers.RMSprop(learning_rate=1e-5), # 기존의 rmsprop보다 학습률을 낮춰 진행\n","              metrics=[\"accuracy\"])\n","\n","callbacks = [\n","    keras.callbacks.ModelCheckpoint(\n","        filepath=\"fine_tuning.keras\",\n","        save_best_only=True,\n","        monitor=\"val_loss\")\n","]\n","history = model.fit(\n","    train_dataset,\n","    epochs=30,\n","    validation_data=validation_dataset,\n","    callbacks=callbacks)"],"metadata":{"id":"H3hB9wd8JKox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["check_train_val_plot(history)"],"metadata":{"id":"SakGyvn1KB4e"},"execution_count":null,"outputs":[]}]}