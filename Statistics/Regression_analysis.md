# 회귀분석

> 과거의 결과값(Data)를 기준으로 미래의 결과값을 예측하는 방법

- 회귀식 : y ~ ax+b
  - 이때 y와 x는 고정값이고 a와 b는 모수(Parameter)이다.
  - y와 x간의 관계를 나타내기위해 = 대신 ~로 표현

- x : 독립변수(Input) / y : 종속변수(Output)
- 최소제곱법(LSM, OLS) 또는 경사하강법(GDM)으로 회귀계수인 a와 b를 추정한다.
  - LSM : 주어진 Data와 회귀선 사이의 제곱합을 최소화하는 방법으로 회귀계수를 추정한다.
  - GDM : 임의의 초기 회귀계수를 설정하고, 학습률(learning rate)과 반복횟수에 따라 기울기를 조절해가며 회귀계수를 추정한다.

- SST : y의 전체 변동
- SSR : 회귀직선(x)으로 설명 되는 변동
- SSE : 회귀직선(x)으로 설명 되지 않는 변동

![이미지 설명](file:///C:/Users/spa84/Pictures/Coding/[2023.07.12]_Python_Statistics.png)

- 결정계수(R^2) = SSR/SST
  - 회귀직선으로 설명 되는 변동이 전체변동에서 얼마만큼을 차지하는지 나타낸다.
- MSE = SSE/SST
  - 회귀직선으로 설명 되지 않는 변동이 전체변동에서 얼마만큼을 차지하는지 나타낸다.
  - 결정계수와 trade-off 관계이다.

## 다중 회귀 분석

> 지금까지는 독립변수가 하나인 단일 회귀 분석을 이야기 하였다. 다중 회귀 분석은 종속변수에 영향을 주는 독립변수가 여러 개인 경우이다.

- 다중공선성 : 독립 변수간 강한 상관관계가 있는 경우 발생하고, 회귀 분석 결과를 신뢰할 수 없게 만든다.
  - 분산팽창요인(VIF) : 각 독립 변수의 설명력을 다른 독립 변수들을 사용하여 평가하는 지표로 값이 10이상일 경우 다중공선성 문제가 의심된다.
  - 문제해결을 위해서는 독립변수들 중의 일부를 제거해야 한다.
- 수정 결정계수(Adjusted R^2) : 독립변수가 증가하여 R^2값이 증가하는 문제를 해결하기 위해 다중회귀분석에서 사용되는 결정계수
  - Adjusted R^2 = 1 - (n-1)/(n-p-1)(1-R^2)와 같이 독립변수의 개수 p값을 분모에 적용하여 R^2이 증가하는 영향을 감소시킨다.